xFormers not available
Command Line Args: Namespace(config_file='configs/clipart1k/vitb_shot5_clipart1k_finetune.yaml', resume=False, eval_only=True, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/clipart1k_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/clipart1k_5shot/', 'SOLVER.IMS_PER_BATCH', '4'])
xFormers not available
xFormers not available
xFormers not available
xFormers not available
[12/23 19:26:27 detectron2]: Rank of current process: 0. World size: 4
[12/23 19:26:28 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/23 19:26:28 detectron2]: Command line arguments: Namespace(config_file='configs/clipart1k/vitb_shot5_clipart1k_finetune.yaml', resume=False, eval_only=True, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/clipart1k_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/clipart1k_5shot/', 'SOLVER.IMS_PER_BATCH', '4'])
[12/23 19:26:28 detectron2]: Contents of args.config_file=configs/clipart1k/vitb_shot5_clipart1k_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/clipart1k_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("clipart1k_5shot",)
  TEST: ("clipart1k_test",)
TEST:
  EVAL_PERIOD: 250
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (100, 180)
  MAX_ITER: 250
  WARMUP_ITERS: 50
  CHECKPOINT_PERIOD: 250
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 19:26:28 detectron2]: Full config saved to output/vitb/clipart1k_5shot/config.yaml
('clipart1k_test',)
[12/23 19:26:34 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vitb/clipart1k_5shot/model_final.pth ...
[12/23 19:26:38 d2.data.datasets.coco]: Loaded 500 images in COCO format from datasets/clipart1k/annotations/test.json
[12/23 19:26:38 d2.data.build]: Distribution of instances among all 20 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|   sheep    | 33           |    chair    | 163          |    boat     | 74           |
|   bottle   | 74           | diningtable | 50           |    sofa     | 21           |
|    cow     | 21           |  motorbike  | 10           |     car     | 84           |
| aeroplane  | 41           |     cat     | 23           |    train    | 26           |
|   person   | 566          |   bicycle   | 16           | pottedplant | 94           |
|    bird    | 124          |     dog     | 24           |     bus     | 8            |
| tvmonitor  | 40           |    horse    | 34           |             |              |
|   total    | 1526         |             |              |             |              |
[12/23 19:26:38 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/23 19:26:38 d2.data.common]: Serializing 500 elements to byte tensors and concatenating them all ...
[12/23 19:26:38 d2.data.common]: Serialized dataset takes 0.18 MiB
('clipart1k_test',)
[12/23 19:26:38 d2.evaluation.evaluator]: Start inference on 125 batches
('clipart1k_test',)
('clipart1k_test',)
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
xFormers not available
xFormers not available
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
xFormers not available
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/23 19:27:18 d2.evaluation.evaluator]: Inference done 11/125. Dataloading: 0.0011 s / iter. Inference: 1.7166 s / iter. Eval: 0.0003 s / iter. Total: 1.7180 s / iter. ETA=0:03:15
[12/23 19:27:23 d2.evaluation.evaluator]: Inference done 13/125. Dataloading: 0.0012 s / iter. Inference: 1.9654 s / iter. Eval: 0.0003 s / iter. Total: 1.9670 s / iter. ETA=0:03:40
[12/23 19:27:30 d2.evaluation.evaluator]: Inference done 17/125. Dataloading: 0.0013 s / iter. Inference: 1.8816 s / iter. Eval: 0.0003 s / iter. Total: 1.8833 s / iter. ETA=0:03:23
[12/23 19:27:35 d2.evaluation.evaluator]: Inference done 19/125. Dataloading: 0.0014 s / iter. Inference: 1.9764 s / iter. Eval: 0.0003 s / iter. Total: 1.9782 s / iter. ETA=0:03:29
[12/23 19:27:42 d2.evaluation.evaluator]: Inference done 22/125. Dataloading: 0.0015 s / iter. Inference: 2.0115 s / iter. Eval: 0.0003 s / iter. Total: 2.0134 s / iter. ETA=0:03:27
[12/23 19:27:48 d2.evaluation.evaluator]: Inference done 25/125. Dataloading: 0.0015 s / iter. Inference: 2.0050 s / iter. Eval: 0.0003 s / iter. Total: 2.0070 s / iter. ETA=0:03:20
[12/23 19:27:53 d2.evaluation.evaluator]: Inference done 28/125. Dataloading: 0.0016 s / iter. Inference: 1.9809 s / iter. Eval: 0.0003 s / iter. Total: 1.9830 s / iter. ETA=0:03:12
[12/23 19:27:59 d2.evaluation.evaluator]: Inference done 31/125. Dataloading: 0.0017 s / iter. Inference: 1.9860 s / iter. Eval: 0.0003 s / iter. Total: 1.9881 s / iter. ETA=0:03:06
[12/23 19:28:05 d2.evaluation.evaluator]: Inference done 34/125. Dataloading: 0.0017 s / iter. Inference: 1.9874 s / iter. Eval: 0.0003 s / iter. Total: 1.9896 s / iter. ETA=0:03:01
[12/23 19:28:11 d2.evaluation.evaluator]: Inference done 37/125. Dataloading: 0.0017 s / iter. Inference: 1.9710 s / iter. Eval: 0.0003 s / iter. Total: 1.9732 s / iter. ETA=0:02:53
[12/23 19:28:17 d2.evaluation.evaluator]: Inference done 40/125. Dataloading: 0.0018 s / iter. Inference: 1.9731 s / iter. Eval: 0.0003 s / iter. Total: 1.9753 s / iter. ETA=0:02:47
[12/23 19:28:23 d2.evaluation.evaluator]: Inference done 44/125. Dataloading: 0.0018 s / iter. Inference: 1.9210 s / iter. Eval: 0.0003 s / iter. Total: 1.9233 s / iter. ETA=0:02:35
[12/23 19:28:30 d2.evaluation.evaluator]: Inference done 47/125. Dataloading: 0.0018 s / iter. Inference: 1.9604 s / iter. Eval: 0.0003 s / iter. Total: 1.9627 s / iter. ETA=0:02:33
[12/23 19:28:36 d2.evaluation.evaluator]: Inference done 50/125. Dataloading: 0.0018 s / iter. Inference: 1.9583 s / iter. Eval: 0.0003 s / iter. Total: 1.9606 s / iter. ETA=0:02:27
[12/23 19:28:42 d2.evaluation.evaluator]: Inference done 53/125. Dataloading: 0.0018 s / iter. Inference: 1.9652 s / iter. Eval: 0.0003 s / iter. Total: 1.9675 s / iter. ETA=0:02:21
[12/23 19:28:48 d2.evaluation.evaluator]: Inference done 56/125. Dataloading: 0.0018 s / iter. Inference: 1.9728 s / iter. Eval: 0.0003 s / iter. Total: 1.9751 s / iter. ETA=0:02:16
[12/23 19:28:54 d2.evaluation.evaluator]: Inference done 60/125. Dataloading: 0.0018 s / iter. Inference: 1.9342 s / iter. Eval: 0.0003 s / iter. Total: 1.9365 s / iter. ETA=0:02:05
[12/23 19:29:01 d2.evaluation.evaluator]: Inference done 63/125. Dataloading: 0.0018 s / iter. Inference: 1.9465 s / iter. Eval: 0.0003 s / iter. Total: 1.9488 s / iter. ETA=0:02:00
[12/23 19:29:07 d2.evaluation.evaluator]: Inference done 66/125. Dataloading: 0.0018 s / iter. Inference: 1.9476 s / iter. Eval: 0.0003 s / iter. Total: 1.9499 s / iter. ETA=0:01:55
[12/23 19:29:12 d2.evaluation.evaluator]: Inference done 70/125. Dataloading: 0.0018 s / iter. Inference: 1.9095 s / iter. Eval: 0.0003 s / iter. Total: 1.9118 s / iter. ETA=0:01:45
[12/23 19:29:17 d2.evaluation.evaluator]: Inference done 73/125. Dataloading: 0.0018 s / iter. Inference: 1.9063 s / iter. Eval: 0.0003 s / iter. Total: 1.9086 s / iter. ETA=0:01:39
[12/23 19:29:23 d2.evaluation.evaluator]: Inference done 77/125. Dataloading: 0.0018 s / iter. Inference: 1.8840 s / iter. Eval: 0.0003 s / iter. Total: 1.8863 s / iter. ETA=0:01:30
[12/23 19:29:30 d2.evaluation.evaluator]: Inference done 80/125. Dataloading: 0.0018 s / iter. Inference: 1.8975 s / iter. Eval: 0.0003 s / iter. Total: 1.8998 s / iter. ETA=0:01:25
[12/23 19:29:35 d2.evaluation.evaluator]: Inference done 82/125. Dataloading: 0.0018 s / iter. Inference: 1.9156 s / iter. Eval: 0.0003 s / iter. Total: 1.9179 s / iter. ETA=0:01:22
[12/23 19:29:43 d2.evaluation.evaluator]: Inference done 85/125. Dataloading: 0.0018 s / iter. Inference: 1.9373 s / iter. Eval: 0.0003 s / iter. Total: 1.9397 s / iter. ETA=0:01:17
[12/23 19:29:48 d2.evaluation.evaluator]: Inference done 88/125. Dataloading: 0.0018 s / iter. Inference: 1.9316 s / iter. Eval: 0.0003 s / iter. Total: 1.9340 s / iter. ETA=0:01:11
[12/23 19:29:54 d2.evaluation.evaluator]: Inference done 91/125. Dataloading: 0.0018 s / iter. Inference: 1.9308 s / iter. Eval: 0.0003 s / iter. Total: 1.9331 s / iter. ETA=0:01:05
[12/23 19:30:00 d2.evaluation.evaluator]: Inference done 94/125. Dataloading: 0.0018 s / iter. Inference: 1.9374 s / iter. Eval: 0.0003 s / iter. Total: 1.9397 s / iter. ETA=0:01:00
[12/23 19:30:07 d2.evaluation.evaluator]: Inference done 97/125. Dataloading: 0.0018 s / iter. Inference: 1.9513 s / iter. Eval: 0.0003 s / iter. Total: 1.9536 s / iter. ETA=0:00:54
[12/23 19:30:13 d2.evaluation.evaluator]: Inference done 99/125. Dataloading: 0.0018 s / iter. Inference: 1.9652 s / iter. Eval: 0.0003 s / iter. Total: 1.9675 s / iter. ETA=0:00:51
[12/23 19:30:19 d2.evaluation.evaluator]: Inference done 101/125. Dataloading: 0.0018 s / iter. Inference: 1.9939 s / iter. Eval: 0.0003 s / iter. Total: 1.9962 s / iter. ETA=0:00:47
[12/23 19:30:25 d2.evaluation.evaluator]: Inference done 104/125. Dataloading: 0.0018 s / iter. Inference: 1.9956 s / iter. Eval: 0.0003 s / iter. Total: 1.9978 s / iter. ETA=0:00:41
[12/23 19:30:32 d2.evaluation.evaluator]: Inference done 107/125. Dataloading: 0.0018 s / iter. Inference: 2.0058 s / iter. Eval: 0.0003 s / iter. Total: 2.0081 s / iter. ETA=0:00:36
[12/23 19:30:38 d2.evaluation.evaluator]: Inference done 110/125. Dataloading: 0.0018 s / iter. Inference: 2.0034 s / iter. Eval: 0.0003 s / iter. Total: 2.0057 s / iter. ETA=0:00:30
[12/23 19:30:44 d2.evaluation.evaluator]: Inference done 112/125. Dataloading: 0.0018 s / iter. Inference: 2.0209 s / iter. Eval: 0.0003 s / iter. Total: 2.0232 s / iter. ETA=0:00:26
[12/23 19:30:50 d2.evaluation.evaluator]: Inference done 115/125. Dataloading: 0.0018 s / iter. Inference: 2.0163 s / iter. Eval: 0.0003 s / iter. Total: 2.0186 s / iter. ETA=0:00:20
[12/23 19:30:55 d2.evaluation.evaluator]: Inference done 118/125. Dataloading: 0.0018 s / iter. Inference: 2.0073 s / iter. Eval: 0.0003 s / iter. Total: 2.0096 s / iter. ETA=0:00:14
[12/23 19:31:00 d2.evaluation.evaluator]: Inference done 120/125. Dataloading: 0.0018 s / iter. Inference: 2.0173 s / iter. Eval: 0.0003 s / iter. Total: 2.0195 s / iter. ETA=0:00:10
[12/23 19:31:06 d2.evaluation.evaluator]: Inference done 123/125. Dataloading: 0.0018 s / iter. Inference: 2.0160 s / iter. Eval: 0.0003 s / iter. Total: 2.0183 s / iter. ETA=0:00:04
[12/23 19:31:29 d2.evaluation.evaluator]: Total inference time: 0:04:20.898564 (2.174155 s / iter per device, on 4 devices)
[12/23 19:31:29 d2.evaluation.evaluator]: Total inference pure compute time: 0:04:00 (2.005001 s / iter per device, on 4 devices)
[12/23 19:31:29 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/23 19:31:29 d2.evaluation.coco_evaluation]: Saving results to output/vitb/clipart1k_5shot/inference/coco_instances_results.json
[12/23 19:31:29 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.21s)
creating index...
index created!
[12/23 19:31:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/23 19:31:30 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.32 seconds.
[12/23 19:31:30 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/23 19:31:30 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.10 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.602
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.376
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.554
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.416
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.596
[12/23 19:31:30 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 36.542 | 60.169 | 38.625 | 21.319 | 34.930 | 41.795 |
[12/23 19:31:30 d2.evaluation.coco_evaluation]: target AP50: -1
[12/23 19:31:30 d2.evaluation.coco_evaluation]: base AP50: 0.6016865111231763
[12/23 19:31:30 d2.evaluation.coco_evaluation]: all AP50: 0.6016865111231763
[12/23 19:31:30 d2.evaluation.coco_evaluation]: target AP75: -1
[12/23 19:31:30 d2.evaluation.coco_evaluation]: base AP75: 0.386252935394954
[12/23 19:31:30 d2.evaluation.coco_evaluation]: all AP75: 0.386252935394954
[12/23 19:31:30 d2.evaluation.coco_evaluation]: target mAP: -1.0
[12/23 19:31:30 d2.evaluation.coco_evaluation]: base mAP: 0.3654242639861606
[12/23 19:31:30 d2.evaluation.coco_evaluation]: all mAP: 0.3654242639861606
[12/23 19:31:30 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category   | AP     | category    | AP     | category    | AP     |
|:-----------|:-------|:------------|:-------|:------------|:-------|
| sheep      | 32.220 | chair       | 14.186 | boat        | 34.612 |
| bottle     | 21.588 | diningtable | 32.209 | sofa        | 34.581 |
| cow        | 51.468 | motorbike   | 71.736 | car         | 46.778 |
| aeroplane  | 43.222 | cat         | 19.762 | train       | 49.100 |
| person     | 20.503 | bicycle     | 54.385 | pottedplant | 22.064 |
| bird       | 23.851 | dog         | 18.290 | bus         | 68.574 |
| tvmonitor  | 35.034 | horse       | 36.685 |             |        |
[12/23 19:31:30 d2.engine.defaults]: Evaluation results for clipart1k_test in csv format:
[12/23 19:31:30 d2.evaluation.testing]: copypaste: Task: bbox
[12/23 19:31:30 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/23 19:31:30 d2.evaluation.testing]: copypaste: 36.5424,60.1687,38.6253,21.3194,34.9305,41.7953
[12/23 19:31:30 d2.evaluation.testing]: ###################### ('AP', 36.542426398616065) ######################
