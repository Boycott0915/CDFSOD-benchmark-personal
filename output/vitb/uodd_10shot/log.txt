[12/22 20:11:24] detectron2 INFO: Rank of current process: 0. World size: 4
[12/22 20:11:25] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/22 20:11:25] detectron2 INFO: Command line arguments: Namespace(config_file='configs/uodd/vitb_shot10_uodd_finetune.yaml', resume=False, eval_only=False, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'weights/trained/few-shot/vitb_0089999.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/uodd_10shot/'])
[12/22 20:11:25] detectron2 INFO: Contents of args.config_file=configs/uodd/vitb_shot10_uodd_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/UODD_10shot.vitb14.bbox.p10.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 3
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("UODD_10shot",)
  TEST: ("UODD_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/22 20:11:25] detectron2 INFO: Full config saved to output/vitb/uodd_10shot/config.yaml
[12/22 22:40:11] detectron2 INFO: Rank of current process: 0. World size: 4
[12/22 22:40:11] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/22 22:40:11] detectron2 INFO: Command line arguments: Namespace(config_file='configs/uodd/vitb_shot10_uodd_finetune.yaml', resume=False, eval_only=False, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'weights/trained/few-shot/vitb_0089999.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/uodd_10shot/'])
[12/22 22:40:11] detectron2 INFO: Contents of args.config_file=configs/uodd/vitb_shot10_uodd_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/UODD_10shot.vitb14.bbox.p10.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 3
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("UODD_10shot",)
  TEST: ("UODD_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/22 22:40:11] detectron2 INFO: Full config saved to output/vitb/uodd_10shot/config.yaml
[12/22 22:40:17] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[12/22 22:40:17] d2.data.datasets.coco INFO: Loaded 20 images in COCO format from datasets/UODD/annotations/10_shot.json
[12/22 22:40:17] d2.data.build INFO: Removed 0 images with no usable annotations. 20 images left.
[12/22 22:40:17] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|  category   | #instances   |  category  | #instances   |  category  | #instances   |
|:-----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| seacucumber | 10           | seaurchin  | 10           |  scallop   | 10           |
|             |              |            |              |            |              |
|    total    | 30           |            |              |            |              |[0m
[12/22 22:40:17] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[12/22 22:40:17] d2.data.build INFO: Using training sampler TrainingSampler
[12/22 22:40:17] d2.data.common INFO: Serializing 20 elements to byte tensors and concatenating them all ...
[12/22 22:40:17] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[12/22 22:40:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from weights/trained/few-shot/vitb_0089999.pth ...
[12/22 22:40:18] fvcore.common.checkpoint WARNING: Skip loading parameter 'test_class_weight' to the model due to incompatible shapes: (80, 768) in the checkpoint but (3, 768) in the model! You might want to double check if this is expected.
[12/22 22:40:18] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34madapter.proto_center_attn.attention_weights.0.{bias, weight}[0m
[34madapter.proto_center_attn.fc.{bias, weight}[0m
[34mbg_tokens.weight[0m
[34mclass_weights.weight[0m
[34mdomain_prompter.weight[0m
[34mprototype_classifier.linear.{bias, weight}[0m
[34mtest_class_weight[0m
[12/22 22:40:18] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mtrain_class_weight[0m
[12/22 22:40:18] d2.engine.train_loop INFO: Starting training from iteration 0
[12/22 22:40:42] d2.utils.events INFO:  eta: 0:01:03  iter: 19  roi_cover_ratio: 0.9111  cls_acc: 0.8779  fg_cls_acc: 0.4667  false_neg_ratio: 0.4139  total_loss: 4.835  aux_bce_loss_0: 0.3054  aux_dice_loss_0: 0.2107  rg_l1_loss_0: 0.05432  aux_bce_loss_1: 0.2524  aux_dice_loss_1: 0.1789  rg_l1_loss_1: 0.04601  aux_bce_loss_2: 0.2284  aux_dice_loss_2: 0.157  rg_l1_loss_2: 0.04065  aux_bce_loss_3: 0.2169  aux_dice_loss_3: 0.1483  rg_l1_loss_3: 0.0396  aux_bce_loss_4: 0.2133  aux_dice_loss_4: 0.1438  rg_l1_loss_4: 0.03952  focal_loss_0: 0.1086  focal_loss_1: 0.1217  focal_loss_2: 0.114  bbox_loss: 0.1314  domain_prompter_contrasitive_loss: 0.000316  prototype_cls_loss: 1.099  proto_contrastive_loss: 1.032  time: 0.8000  data_time: 0.3522  lr: 0.0019001  max_mem: 2573M
[12/22 22:40:58] d2.utils.events INFO:  eta: 0:00:48  iter: 39  roi_cover_ratio: 0.8991  cls_acc: 0.9326  fg_cls_acc: 0.8929  false_neg_ratio: 0.09124  total_loss: 4.046  aux_bce_loss_0: 0.2509  aux_dice_loss_0: 0.1712  rg_l1_loss_0: 0.04249  aux_bce_loss_1: 0.1902  aux_dice_loss_1: 0.1343  rg_l1_loss_1: 0.03268  aux_bce_loss_2: 0.1574  aux_dice_loss_2: 0.1102  rg_l1_loss_2: 0.02835  aux_bce_loss_3: 0.1426  aux_dice_loss_3: 0.1016  rg_l1_loss_3: 0.0274  aux_bce_loss_4: 0.1389  aux_dice_loss_4: 0.1002  rg_l1_loss_4: 0.02644  focal_loss_0: 0.05989  focal_loss_1: 0.0408  focal_loss_2: 0.04029  bbox_loss: 0.08918  domain_prompter_contrasitive_loss: 0.000316  prototype_cls_loss: 1.072  proto_contrastive_loss: 1.028  time: 0.8041  data_time: 0.0067  lr: 0.002  max_mem: 2706M
[12/22 22:41:14] d2.utils.events INFO:  eta: 0:00:32  iter: 59  roi_cover_ratio: 0.8944  cls_acc: 0.9707  fg_cls_acc: 0.942  false_neg_ratio: 0.04058  total_loss: 3.559  aux_bce_loss_0: 0.2267  aux_dice_loss_0: 0.1579  rg_l1_loss_0: 0.03791  aux_bce_loss_1: 0.1595  aux_dice_loss_1: 0.11  rg_l1_loss_1: 0.02616  aux_bce_loss_2: 0.1255  aux_dice_loss_2: 0.08489  rg_l1_loss_2: 0.02194  aux_bce_loss_3: 0.1097  aux_dice_loss_3: 0.07516  rg_l1_loss_3: 0.01999  aux_bce_loss_4: 0.1028  aux_dice_loss_4: 0.07239  rg_l1_loss_4: 0.01865  focal_loss_0: 0.02564  focal_loss_1: 0.02367  focal_loss_2: 0.02174  bbox_loss: 0.06277  domain_prompter_contrasitive_loss: 0.000316  prototype_cls_loss: 1.033  proto_contrastive_loss: 1.026  time: 0.8075  data_time: 0.0067  lr: 0.0002  max_mem: 2724M
[12/22 22:41:30] d2.utils.events INFO:  eta: 0:00:16  iter: 79  roi_cover_ratio: 0.909  cls_acc: 0.9805  fg_cls_acc: 0.9551  false_neg_ratio: 0.04495  total_loss: 3.402  aux_bce_loss_0: 0.2147  aux_dice_loss_0: 0.1525  rg_l1_loss_0: 0.03627  aux_bce_loss_1: 0.1441  aux_dice_loss_1: 0.1036  rg_l1_loss_1: 0.02385  aux_bce_loss_2: 0.1089  aux_dice_loss_2: 0.07667  rg_l1_loss_2: 0.01955  aux_bce_loss_3: 0.09416  aux_dice_loss_3: 0.06641  rg_l1_loss_3: 0.01788  aux_bce_loss_4: 0.08835  aux_dice_loss_4: 0.06404  rg_l1_loss_4: 0.01696  focal_loss_0: 0.02273  focal_loss_1: 0.01924  focal_loss_2: 0.01802  bbox_loss: 0.05581  domain_prompter_contrasitive_loss: 0.000316  prototype_cls_loss: 1.029  proto_contrastive_loss: 1.026  time: 0.8090  data_time: 0.0068  lr: 0.0002  max_mem: 2724M
[12/22 22:41:47] fvcore.common.checkpoint INFO: Saving checkpoint to output/vitb/uodd_10shot/model_0000099.pth
[12/22 22:41:47] fvcore.common.checkpoint INFO: Saving checkpoint to output/vitb/uodd_10shot/model_final.pth
[12/22 22:41:48] d2.utils.events INFO:  eta: 0:00:00  iter: 99  roi_cover_ratio: 0.9118  cls_acc: 0.9727  fg_cls_acc: 0.9657  false_neg_ratio: 0.03083  total_loss: 3.368  aux_bce_loss_0: 0.2081  aux_dice_loss_0: 0.1519  rg_l1_loss_0: 0.03409  aux_bce_loss_1: 0.1383  aux_dice_loss_1: 0.1009  rg_l1_loss_1: 0.02322  aux_bce_loss_2: 0.1049  aux_dice_loss_2: 0.07529  rg_l1_loss_2: 0.01868  aux_bce_loss_3: 0.08955  aux_dice_loss_3: 0.06493  rg_l1_loss_3: 0.01675  aux_bce_loss_4: 0.08563  aux_dice_loss_4: 0.06277  rg_l1_loss_4: 0.01608  focal_loss_0: 0.02208  focal_loss_1: 0.01751  focal_loss_2: 0.01756  bbox_loss: 0.05473  domain_prompter_contrasitive_loss: 0.000316  prototype_cls_loss: 1.026  proto_contrastive_loss: 1.026  time: 0.8106  data_time: 0.0066  lr: 2e-05  max_mem: 2724M
[12/22 22:41:48] d2.engine.hooks INFO: Overall training speed: 98 iterations in 0:01:19 (0.8106 s / it)
[12/22 22:41:48] d2.engine.hooks INFO: Total training time: 0:01:21 (0:00:01 on hooks)
[12/22 22:41:48] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[12/22 22:41:48] d2.data.datasets.coco INFO: Loaded 506 images in COCO format from datasets/UODD/annotations/test.json
[12/22 22:41:48] d2.data.build INFO: Distribution of instances among all 3 categories:
[36m|  category   | #instances   |  category  | #instances   |  category  | #instances   |
|:-----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| seacucumber | 739          | seaurchin  | 2216         |  scallop   | 263          |
|             |              |            |              |            |              |
|    total    | 3218         |            |              |            |              |[0m
[12/22 22:41:48] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/22 22:41:48] d2.data.common INFO: Serializing 506 elements to byte tensors and concatenating them all ...
[12/22 22:41:48] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[12/22 22:41:48] d2.evaluation.evaluator INFO: Start inference on 127 batches
[12/22 22:42:09] d2.evaluation.evaluator INFO: Inference done 11/127. Dataloading: 0.0012 s / iter. Inference: 0.2361 s / iter. Eval: 0.0003 s / iter. Total: 0.2376 s / iter. ETA=0:00:27
[12/22 22:42:14] d2.evaluation.evaluator INFO: Inference done 33/127. Dataloading: 0.0016 s / iter. Inference: 0.2344 s / iter. Eval: 0.0002 s / iter. Total: 0.2362 s / iter. ETA=0:00:22
[12/22 22:42:19] d2.evaluation.evaluator INFO: Inference done 43/127. Dataloading: 0.0016 s / iter. Inference: 0.3049 s / iter. Eval: 0.0003 s / iter. Total: 0.3068 s / iter. ETA=0:00:25
[12/22 22:42:24] d2.evaluation.evaluator INFO: Inference done 56/127. Dataloading: 0.0015 s / iter. Inference: 0.3249 s / iter. Eval: 0.0003 s / iter. Total: 0.3268 s / iter. ETA=0:00:23
[12/22 22:42:30] d2.evaluation.evaluator INFO: Inference done 75/127. Dataloading: 0.0015 s / iter. Inference: 0.3103 s / iter. Eval: 0.0003 s / iter. Total: 0.3121 s / iter. ETA=0:00:16
[12/22 22:42:35] d2.evaluation.evaluator INFO: Inference done 95/127. Dataloading: 0.0015 s / iter. Inference: 0.2989 s / iter. Eval: 0.0003 s / iter. Total: 0.3008 s / iter. ETA=0:00:09
[12/22 22:42:40] d2.evaluation.evaluator INFO: Inference done 112/127. Dataloading: 0.0015 s / iter. Inference: 0.2993 s / iter. Eval: 0.0003 s / iter. Total: 0.3012 s / iter. ETA=0:00:04
[12/22 22:43:04] d2.evaluation.evaluator INFO: Total inference time: 0:00:56.408766 (0.462367 s / iter per device, on 4 devices)
[12/22 22:43:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:36 (0.296328 s / iter per device, on 4 devices)
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: Saving results to output/vitb/uodd_10shot/inference/coco_instances_results.json
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[12/22 22:43:05] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[12/22 22:43:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.20 seconds.
[12/22 22:43:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[12/22 22:43:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.05 seconds.
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 6.545 | 12.968 | 5.790  | 4.615 | 8.398 | 15.794 |
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: target AP50: -1
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: base AP50: 0.12968246047151827
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: all AP50: 0.12968246047151827
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: target AP75: -1
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: base AP75: 0.057898009734496284
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: all AP75: 0.057898009734496284
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: target mAP: -1.0
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: base mAP: 0.06545269931600202
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: all mAP: 0.06545269931600202
[12/22 22:43:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category    | AP    | category   | AP    | category   | AP     |
|:------------|:------|:-----------|:------|:-----------|:-------|
| seacucumber | 0.544 | seaurchin  | 7.651 | scallop    | 11.441 |
[12/22 22:43:05] d2.engine.defaults INFO: Evaluation results for UODD_test in csv format:
[12/22 22:43:05] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/22 22:43:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/22 22:43:05] d2.evaluation.testing INFO: copypaste: 6.5453,12.9682,5.7898,4.6155,8.3982,15.7940
[12/22 22:43:05] d2.evaluation.testing INFO: ###################### ('AP', 6.545269931600202) ######################
[12/23 20:09:45] detectron2 INFO: Rank of current process: 0. World size: 4
[12/23 20:09:45] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/23 20:09:45] detectron2 INFO: Command line arguments: Namespace(config_file='configs/uodd/vitb_shot10_uodd_finetune.yaml', resume=False, eval_only=True, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/uodd_10shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/uodd_10shot/', 'SOLVER.IMS_PER_BATCH', '4', 'INPUT.MIN_SIZE_TEST', '600', 'INPUT.MAX_SIZE_TEST', '1000'])
[12/23 20:09:45] detectron2 INFO: Contents of args.config_file=configs/uodd/vitb_shot10_uodd_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/UODD_10shot.vitb14.bbox.p10.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 3
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("UODD_10shot",)
  TEST: ("UODD_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 20:09:46] detectron2 INFO: Full config saved to output/vitb/uodd_10shot/config.yaml
[12/23 20:09:52] fvcore.common.checkpoint INFO: [Checkpointer] Loading from output/vitb/uodd_10shot/model_final.pth ...
[12/23 20:09:56] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[12/23 20:09:56] d2.data.datasets.coco INFO: Loaded 506 images in COCO format from datasets/UODD/annotations/test.json
[12/23 20:09:56] d2.data.build INFO: Distribution of instances among all 3 categories:
|  category   | #instances   |  category  | #instances   |  category  | #instances   |
|:-----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| seacucumber | 739          | seaurchin  | 2216         |  scallop   | 263          |
|             |              |            |              |            |              |
|    total    | 3218         |            |              |            |              |
[12/23 20:09:56] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1000, sample_style='choice')]
[12/23 20:09:56] d2.data.common INFO: Serializing 506 elements to byte tensors and concatenating them all ...
[12/23 20:09:56] d2.data.common INFO: Serialized dataset takes 0.19 MiB
[12/23 20:09:57] d2.evaluation.evaluator INFO: Start inference on 127 batches
[12/23 20:10:22] d2.evaluation.evaluator INFO: Inference done 11/127. Dataloading: 0.0011 s / iter. Inference: 0.5144 s / iter. Eval: 0.0003 s / iter. Total: 0.5158 s / iter. ETA=0:00:59
[12/23 20:10:27] d2.evaluation.evaluator INFO: Inference done 19/127. Dataloading: 0.0014 s / iter. Inference: 0.6170 s / iter. Eval: 0.0003 s / iter. Total: 0.6187 s / iter. ETA=0:01:06
[12/23 20:10:32] d2.evaluation.evaluator INFO: Inference done 29/127. Dataloading: 0.0015 s / iter. Inference: 0.5708 s / iter. Eval: 0.0003 s / iter. Total: 0.5727 s / iter. ETA=0:00:56
[12/23 20:10:38] d2.evaluation.evaluator INFO: Inference done 35/127. Dataloading: 0.0015 s / iter. Inference: 0.6333 s / iter. Eval: 0.0003 s / iter. Total: 0.6353 s / iter. ETA=0:00:58
[12/23 20:10:44] d2.evaluation.evaluator INFO: Inference done 40/127. Dataloading: 0.0016 s / iter. Inference: 0.7080 s / iter. Eval: 0.0003 s / iter. Total: 0.7100 s / iter. ETA=0:01:01
[12/23 20:10:49] d2.evaluation.evaluator INFO: Inference done 44/127. Dataloading: 0.0016 s / iter. Inference: 0.7661 s / iter. Eval: 0.0003 s / iter. Total: 0.7681 s / iter. ETA=0:01:03
[12/23 20:10:55] d2.evaluation.evaluator INFO: Inference done 49/127. Dataloading: 0.0015 s / iter. Inference: 0.8215 s / iter. Eval: 0.0003 s / iter. Total: 0.8235 s / iter. ETA=0:01:04
[12/23 20:11:00] d2.evaluation.evaluator INFO: Inference done 53/127. Dataloading: 0.0015 s / iter. Inference: 0.8641 s / iter. Eval: 0.0003 s / iter. Total: 0.8661 s / iter. ETA=0:01:04
[12/23 20:11:06] d2.evaluation.evaluator INFO: Inference done 57/127. Dataloading: 0.0015 s / iter. Inference: 0.9114 s / iter. Eval: 0.0003 s / iter. Total: 0.9134 s / iter. ETA=0:01:03
[12/23 20:11:12] d2.evaluation.evaluator INFO: Inference done 62/127. Dataloading: 0.0015 s / iter. Inference: 0.9305 s / iter. Eval: 0.0003 s / iter. Total: 0.9325 s / iter. ETA=0:01:00
[12/23 20:11:18] d2.evaluation.evaluator INFO: Inference done 68/127. Dataloading: 0.0015 s / iter. Inference: 0.9358 s / iter. Eval: 0.0003 s / iter. Total: 0.9378 s / iter. ETA=0:00:55
[12/23 20:11:23] d2.evaluation.evaluator INFO: Inference done 73/127. Dataloading: 0.0015 s / iter. Inference: 0.9483 s / iter. Eval: 0.0003 s / iter. Total: 0.9503 s / iter. ETA=0:00:51
[12/23 20:11:29] d2.evaluation.evaluator INFO: Inference done 78/127. Dataloading: 0.0015 s / iter. Inference: 0.9571 s / iter. Eval: 0.0003 s / iter. Total: 0.9591 s / iter. ETA=0:00:46
[12/23 20:11:34] d2.evaluation.evaluator INFO: Inference done 83/127. Dataloading: 0.0015 s / iter. Inference: 0.9683 s / iter. Eval: 0.0003 s / iter. Total: 0.9703 s / iter. ETA=0:00:42
[12/23 20:11:40] d2.evaluation.evaluator INFO: Inference done 88/127. Dataloading: 0.0015 s / iter. Inference: 0.9801 s / iter. Eval: 0.0003 s / iter. Total: 0.9820 s / iter. ETA=0:00:38
[12/23 20:11:46] d2.evaluation.evaluator INFO: Inference done 94/127. Dataloading: 0.0014 s / iter. Inference: 0.9755 s / iter. Eval: 0.0003 s / iter. Total: 0.9774 s / iter. ETA=0:00:32
[12/23 20:11:52] d2.evaluation.evaluator INFO: Inference done 100/127. Dataloading: 0.0014 s / iter. Inference: 0.9767 s / iter. Eval: 0.0003 s / iter. Total: 0.9786 s / iter. ETA=0:00:26
[12/23 20:11:58] d2.evaluation.evaluator INFO: Inference done 104/127. Dataloading: 0.0014 s / iter. Inference: 1.0018 s / iter. Eval: 0.0003 s / iter. Total: 1.0038 s / iter. ETA=0:00:23
[12/23 20:12:05] d2.evaluation.evaluator INFO: Inference done 109/127. Dataloading: 0.0014 s / iter. Inference: 1.0189 s / iter. Eval: 0.0003 s / iter. Total: 1.0208 s / iter. ETA=0:00:18
[12/23 20:12:11] d2.evaluation.evaluator INFO: Inference done 114/127. Dataloading: 0.0014 s / iter. Inference: 1.0312 s / iter. Eval: 0.0003 s / iter. Total: 1.0332 s / iter. ETA=0:00:13
[12/23 20:12:17] d2.evaluation.evaluator INFO: Inference done 117/127. Dataloading: 0.0014 s / iter. Inference: 1.0509 s / iter. Eval: 0.0003 s / iter. Total: 1.0529 s / iter. ETA=0:00:10
[12/23 20:12:23] d2.evaluation.evaluator INFO: Inference done 122/127. Dataloading: 0.0014 s / iter. Inference: 1.0569 s / iter. Eval: 0.0004 s / iter. Total: 1.0588 s / iter. ETA=0:00:05
[12/23 20:12:29] d2.evaluation.evaluator INFO: Inference done 126/127. Dataloading: 0.0014 s / iter. Inference: 1.0713 s / iter. Eval: 0.0004 s / iter. Total: 1.0733 s / iter. ETA=0:00:01
[12/23 20:12:50] d2.evaluation.evaluator INFO: Total inference time: 0:02:31.255720 (1.239801 s / iter per device, on 4 devices)
[12/23 20:12:50] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (1.073675 s / iter per device, on 4 devices)
[12/23 20:13:15] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/23 20:13:15] d2.evaluation.coco_evaluation INFO: Saving results to output/vitb/uodd_10shot/inference/coco_instances_results.json
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[12/23 20:13:16] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[12/23 20:13:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.28 seconds.
[12/23 20:13:16] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[12/23 20:13:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.07 seconds.
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 9.991 | 21.498 | 7.336  | 5.494 | 12.441 | 16.830 |
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: target AP50: -1
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: base AP50: 0.21498267531429552
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: all AP50: 0.21498267531429552
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: target AP75: -1
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: base AP75: 0.07336202397648517
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: all AP75: 0.07336202397648517
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: target mAP: -1.0
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: base mAP: 0.09991286484240196
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: all mAP: 0.09991286484240196
[12/23 20:13:16] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category    | AP    | category   | AP     | category   | AP     |
|:------------|:------|:-----------|:-------|:-----------|:-------|
| seacucumber | 1.359 | seaurchin  | 11.326 | scallop    | 17.288 |
[12/23 20:13:16] d2.engine.defaults INFO: Evaluation results for UODD_test in csv format:
[12/23 20:13:16] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/23 20:13:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/23 20:13:16] d2.evaluation.testing INFO: copypaste: 9.9913,21.4983,7.3362,5.4938,12.4409,16.8296
[12/23 20:13:16] d2.evaluation.testing INFO: ###################### ('AP', 9.991286484240195) ######################
