[12/22 19:15:55] detectron2 INFO: Rank of current process: 0. World size: 4
[12/22 19:15:57] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/22 19:15:57] detectron2 INFO: Command line arguments: Namespace(config_file='configs/artaxor/vitb_shot5_artaxor_finetune.yaml', resume=False, eval_only=False, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'weights/trained/few-shot/vitb_0089999.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/artaxor_5shot/'])
[12/22 19:15:57] detectron2 INFO: Contents of args.config_file=configs/artaxor/vitb_shot5_artaxor_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/ArTaxOr_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("ArTaxOr_5shot",)
  TEST: ("ArTaxOr_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/22 19:15:57] detectron2 INFO: Full config saved to output/vitb/artaxor_5shot/config.yaml
[12/22 19:16:03] d2.data.datasets.coco INFO: Loaded 35 images in COCO format from datasets/ArTaxOr/annotations/5_shot.json
[12/22 19:16:03] d2.data.build INFO: Removed 0 images with no usable annotations. 35 images left.
[12/22 19:16:03] d2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 5            | Coleoptera  | 5            |   Diptera   | 5            |
| Hemiptera  | 5            | Hymenoptera | 5            | Lepidoptera | 5            |
|  Odonata   | 5            |             |              |             |              |
|   total    | 35           |             |              |             |              |[0m
[12/22 19:16:03] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[12/22 19:16:03] d2.data.build INFO: Using training sampler TrainingSampler
[12/22 19:16:03] d2.data.common INFO: Serializing 35 elements to byte tensors and concatenating them all ...
[12/22 19:16:03] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[12/22 19:16:03] fvcore.common.checkpoint INFO: [Checkpointer] Loading from weights/trained/few-shot/vitb_0089999.pth ...
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'test_class_weight' to the model due to incompatible shapes: (80, 1024) in the checkpoint but (7, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.cls_token' to the model due to incompatible shapes: (1, 1, 1024) in the checkpoint but (1, 1, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.pos_embed' to the model due to incompatible shapes: (1, 1370, 1024) in the checkpoint but (1, 1370, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.mask_token' to the model due to incompatible shapes: (1, 1024) in the checkpoint but (1, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.patch_embed.proj.weight' to the model due to incompatible shapes: (1024, 3, 14, 14) in the checkpoint but (768, 3, 14, 14) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.patch_embed.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.0.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.1.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.2.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.3.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.4.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.5.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.6.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.7.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.8.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.9.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.10.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.norm1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.norm1.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.attn.qkv.weight' to the model due to incompatible shapes: (3072, 1024) in the checkpoint but (2304, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.attn.qkv.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (2304,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.attn.proj.weight' to the model due to incompatible shapes: (1024, 1024) in the checkpoint but (768, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.attn.proj.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.ls1.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.norm2.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.norm2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.mlp.fc1.weight' to the model due to incompatible shapes: (4096, 1024) in the checkpoint but (3072, 768) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.mlp.fc1.bias' to the model due to incompatible shapes: (4096,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.mlp.fc2.weight' to the model due to incompatible shapes: (1024, 4096) in the checkpoint but (768, 3072) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.mlp.fc2.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.blocks.11.ls2.gamma' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.norm.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.norm.bias' to the model due to incompatible shapes: (1024,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[12/22 19:16:05] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34madapter.proto_center_attn.attention_weights.0.{bias, weight}[0m
[34madapter.proto_center_attn.fc.{bias, weight}[0m
[34mbackbone.blocks.0.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.0.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.0.ls1.gamma[0m
[34mbackbone.blocks.0.ls2.gamma[0m
[34mbackbone.blocks.0.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.0.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.0.norm1.{bias, weight}[0m
[34mbackbone.blocks.0.norm2.{bias, weight}[0m
[34mbackbone.blocks.1.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.1.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.1.ls1.gamma[0m
[34mbackbone.blocks.1.ls2.gamma[0m
[34mbackbone.blocks.1.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.1.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.1.norm1.{bias, weight}[0m
[34mbackbone.blocks.1.norm2.{bias, weight}[0m
[34mbackbone.blocks.10.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.10.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.10.ls1.gamma[0m
[34mbackbone.blocks.10.ls2.gamma[0m
[34mbackbone.blocks.10.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.10.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.10.norm1.{bias, weight}[0m
[34mbackbone.blocks.10.norm2.{bias, weight}[0m
[34mbackbone.blocks.11.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.11.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.11.ls1.gamma[0m
[34mbackbone.blocks.11.ls2.gamma[0m
[34mbackbone.blocks.11.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.11.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.11.norm1.{bias, weight}[0m
[34mbackbone.blocks.11.norm2.{bias, weight}[0m
[34mbackbone.blocks.2.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.2.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.2.ls1.gamma[0m
[34mbackbone.blocks.2.ls2.gamma[0m
[34mbackbone.blocks.2.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.2.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.2.norm1.{bias, weight}[0m
[34mbackbone.blocks.2.norm2.{bias, weight}[0m
[34mbackbone.blocks.3.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.3.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.3.ls1.gamma[0m
[34mbackbone.blocks.3.ls2.gamma[0m
[34mbackbone.blocks.3.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.3.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.3.norm1.{bias, weight}[0m
[34mbackbone.blocks.3.norm2.{bias, weight}[0m
[34mbackbone.blocks.4.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.4.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.4.ls1.gamma[0m
[34mbackbone.blocks.4.ls2.gamma[0m
[34mbackbone.blocks.4.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.4.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.4.norm1.{bias, weight}[0m
[34mbackbone.blocks.4.norm2.{bias, weight}[0m
[34mbackbone.blocks.5.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.5.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.5.ls1.gamma[0m
[34mbackbone.blocks.5.ls2.gamma[0m
[34mbackbone.blocks.5.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.5.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.5.norm1.{bias, weight}[0m
[34mbackbone.blocks.5.norm2.{bias, weight}[0m
[34mbackbone.blocks.6.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.6.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.6.ls1.gamma[0m
[34mbackbone.blocks.6.ls2.gamma[0m
[34mbackbone.blocks.6.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.6.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.6.norm1.{bias, weight}[0m
[34mbackbone.blocks.6.norm2.{bias, weight}[0m
[34mbackbone.blocks.7.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.7.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.7.ls1.gamma[0m
[34mbackbone.blocks.7.ls2.gamma[0m
[34mbackbone.blocks.7.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.7.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.7.norm1.{bias, weight}[0m
[34mbackbone.blocks.7.norm2.{bias, weight}[0m
[34mbackbone.blocks.8.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.8.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.8.ls1.gamma[0m
[34mbackbone.blocks.8.ls2.gamma[0m
[34mbackbone.blocks.8.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.8.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.8.norm1.{bias, weight}[0m
[34mbackbone.blocks.8.norm2.{bias, weight}[0m
[34mbackbone.blocks.9.attn.proj.{bias, weight}[0m
[34mbackbone.blocks.9.attn.qkv.{bias, weight}[0m
[34mbackbone.blocks.9.ls1.gamma[0m
[34mbackbone.blocks.9.ls2.gamma[0m
[34mbackbone.blocks.9.mlp.fc1.{bias, weight}[0m
[34mbackbone.blocks.9.mlp.fc2.{bias, weight}[0m
[34mbackbone.blocks.9.norm1.{bias, weight}[0m
[34mbackbone.blocks.9.norm2.{bias, weight}[0m
[34mbackbone.norm.{bias, weight}[0m
[34mbackbone.patch_embed.proj.{bias, weight}[0m
[34mbackbone.{cls_token, mask_token, pos_embed}[0m
[34mbg_tokens.weight[0m
[34mclass_weights.weight[0m
[34mdomain_prompter.weight[0m
[34mprototype_classifier.linear.{bias, weight}[0m
[34mtest_class_weight[0m
[12/22 19:16:05] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mtrain_class_weight[0m
  [35mbackbone.blocks.12.norm1.{bias, weight}[0m
  [35mbackbone.blocks.12.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.12.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.12.ls1.gamma[0m
  [35mbackbone.blocks.12.norm2.{bias, weight}[0m
  [35mbackbone.blocks.12.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.12.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.12.ls2.gamma[0m
  [35mbackbone.blocks.13.norm1.{bias, weight}[0m
  [35mbackbone.blocks.13.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.13.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.13.ls1.gamma[0m
  [35mbackbone.blocks.13.norm2.{bias, weight}[0m
  [35mbackbone.blocks.13.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.13.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.13.ls2.gamma[0m
  [35mbackbone.blocks.14.norm1.{bias, weight}[0m
  [35mbackbone.blocks.14.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.14.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.14.ls1.gamma[0m
  [35mbackbone.blocks.14.norm2.{bias, weight}[0m
  [35mbackbone.blocks.14.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.14.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.14.ls2.gamma[0m
  [35mbackbone.blocks.15.norm1.{bias, weight}[0m
  [35mbackbone.blocks.15.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.15.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.15.ls1.gamma[0m
  [35mbackbone.blocks.15.norm2.{bias, weight}[0m
  [35mbackbone.blocks.15.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.15.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.15.ls2.gamma[0m
  [35mbackbone.blocks.16.norm1.{bias, weight}[0m
  [35mbackbone.blocks.16.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.16.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.16.ls1.gamma[0m
  [35mbackbone.blocks.16.norm2.{bias, weight}[0m
  [35mbackbone.blocks.16.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.16.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.16.ls2.gamma[0m
  [35mbackbone.blocks.17.norm1.{bias, weight}[0m
  [35mbackbone.blocks.17.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.17.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.17.ls1.gamma[0m
  [35mbackbone.blocks.17.norm2.{bias, weight}[0m
  [35mbackbone.blocks.17.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.17.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.17.ls2.gamma[0m
  [35mbackbone.blocks.18.norm1.{bias, weight}[0m
  [35mbackbone.blocks.18.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.18.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.18.ls1.gamma[0m
  [35mbackbone.blocks.18.norm2.{bias, weight}[0m
  [35mbackbone.blocks.18.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.18.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.18.ls2.gamma[0m
  [35mbackbone.blocks.19.norm1.{bias, weight}[0m
  [35mbackbone.blocks.19.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.19.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.19.ls1.gamma[0m
  [35mbackbone.blocks.19.norm2.{bias, weight}[0m
  [35mbackbone.blocks.19.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.19.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.19.ls2.gamma[0m
  [35mbackbone.blocks.20.norm1.{bias, weight}[0m
  [35mbackbone.blocks.20.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.20.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.20.ls1.gamma[0m
  [35mbackbone.blocks.20.norm2.{bias, weight}[0m
  [35mbackbone.blocks.20.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.20.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.20.ls2.gamma[0m
  [35mbackbone.blocks.21.norm1.{bias, weight}[0m
  [35mbackbone.blocks.21.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.21.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.21.ls1.gamma[0m
  [35mbackbone.blocks.21.norm2.{bias, weight}[0m
  [35mbackbone.blocks.21.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.21.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.21.ls2.gamma[0m
  [35mbackbone.blocks.22.norm1.{bias, weight}[0m
  [35mbackbone.blocks.22.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.22.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.22.ls1.gamma[0m
  [35mbackbone.blocks.22.norm2.{bias, weight}[0m
  [35mbackbone.blocks.22.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.22.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.22.ls2.gamma[0m
  [35mbackbone.blocks.23.norm1.{bias, weight}[0m
  [35mbackbone.blocks.23.attn.qkv.{bias, weight}[0m
  [35mbackbone.blocks.23.attn.proj.{bias, weight}[0m
  [35mbackbone.blocks.23.ls1.gamma[0m
  [35mbackbone.blocks.23.norm2.{bias, weight}[0m
  [35mbackbone.blocks.23.mlp.fc1.{bias, weight}[0m
  [35mbackbone.blocks.23.mlp.fc2.{bias, weight}[0m
  [35mbackbone.blocks.23.ls2.gamma[0m
[12/22 19:16:05] d2.engine.train_loop INFO: Starting training from iteration 0
[12/22 19:16:11] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/defaults.py", line 510, in run_step
    self._trainer.run_step()
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/modeling/meta_arch/devit.py", line 1308, in forward
    bg_feats = roi_features.transpose(-2, -1) @ self.bg_tokens.weight.t()  # N x spatial x back
RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [512, 768] but got: [512, 1024].
[12/22 19:16:11] d2.engine.hooks INFO: Total training time: 0:00:06 (0:00:00 on hooks)
[12/22 19:16:11] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 1241M
[12/22 19:32:47] detectron2 INFO: Rank of current process: 0. World size: 4
[12/22 19:32:48] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/22 19:32:48] detectron2 INFO: Command line arguments: Namespace(config_file='configs/artaxor/vitb_shot5_artaxor_finetune.yaml', resume=False, eval_only=False, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'weights/trained/few-shot/vitb_0089999.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/artaxor_5shot/'])
[12/22 19:32:48] detectron2 INFO: Contents of args.config_file=configs/artaxor/vitb_shot5_artaxor_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/ArTaxOr_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("ArTaxOr_5shot",)
  TEST: ("ArTaxOr_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/22 19:32:48] detectron2 INFO: Full config saved to output/vitb/artaxor_5shot/config.yaml
[12/22 19:32:54] d2.data.datasets.coco INFO: Loaded 35 images in COCO format from datasets/ArTaxOr/annotations/5_shot.json
[12/22 19:32:54] d2.data.build INFO: Removed 0 images with no usable annotations. 35 images left.
[12/22 19:32:54] d2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 5            | Coleoptera  | 5            |   Diptera   | 5            |
| Hemiptera  | 5            | Hymenoptera | 5            | Lepidoptera | 5            |
|  Odonata   | 5            |             |              |             |              |
|   total    | 35           |             |              |             |              |[0m
[12/22 19:32:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[12/22 19:32:54] d2.data.build INFO: Using training sampler TrainingSampler
[12/22 19:32:54] d2.data.common INFO: Serializing 35 elements to byte tensors and concatenating them all ...
[12/22 19:32:54] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[12/22 19:32:55] fvcore.common.checkpoint INFO: [Checkpointer] Loading from weights/trained/few-shot/vitb_0089999.pth ...
[12/22 19:32:56] fvcore.common.checkpoint WARNING: Skip loading parameter 'test_class_weight' to the model due to incompatible shapes: (80, 768) in the checkpoint but (7, 768) in the model! You might want to double check if this is expected.
[12/22 19:32:56] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34madapter.proto_center_attn.attention_weights.0.{bias, weight}[0m
[34madapter.proto_center_attn.fc.{bias, weight}[0m
[34mbg_tokens.weight[0m
[34mclass_weights.weight[0m
[34mdomain_prompter.weight[0m
[34mprototype_classifier.linear.{bias, weight}[0m
[34mtest_class_weight[0m
[12/22 19:32:56] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mtrain_class_weight[0m
[12/22 19:32:56] d2.engine.train_loop INFO: Starting training from iteration 0
[12/22 19:33:21] d2.utils.events INFO:  eta: 0:01:17  iter: 19  roi_cover_ratio: 0.8388  cls_acc: 0.8545  fg_cls_acc: 0.9063  false_neg_ratio: 0.04406  total_loss: 6.108  aux_bce_loss_0: 0.2936  aux_dice_loss_0: 0.1832  rg_l1_loss_0: 0.0551  aux_bce_loss_1: 0.2343  aux_dice_loss_1: 0.1416  rg_l1_loss_1: 0.03921  aux_bce_loss_2: 0.1773  aux_dice_loss_2: 0.1029  rg_l1_loss_2: 0.02654  aux_bce_loss_3: 0.1364  aux_dice_loss_3: 0.08064  rg_l1_loss_3: 0.02204  aux_bce_loss_4: 0.12  aux_dice_loss_4: 0.07243  rg_l1_loss_4: 0.01904  focal_loss_0: 0.2271  focal_loss_1: 0.1399  focal_loss_2: 0.1151  bbox_loss: 0.1255  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.942  proto_contrastive_loss: 1.84  time: 0.9677  data_time: 0.2974  lr: 0.0019001  max_mem: 3630M
[12/22 19:33:41] d2.utils.events INFO:  eta: 0:00:58  iter: 39  roi_cover_ratio: 0.83  cls_acc: 0.918  fg_cls_acc: 0.975  false_neg_ratio: 0.02502  total_loss: 5.287  aux_bce_loss_0: 0.2425  aux_dice_loss_0: 0.1528  rg_l1_loss_0: 0.04668  aux_bce_loss_1: 0.1671  aux_dice_loss_1: 0.1001  rg_l1_loss_1: 0.02875  aux_bce_loss_2: 0.1191  aux_dice_loss_2: 0.07086  rg_l1_loss_2: 0.01959  aux_bce_loss_3: 0.08935  aux_dice_loss_3: 0.05488  rg_l1_loss_3: 0.01488  aux_bce_loss_4: 0.07228  aux_dice_loss_4: 0.04892  rg_l1_loss_4: 0.01221  focal_loss_0: 0.0954  focal_loss_1: 0.05313  focal_loss_2: 0.04487  bbox_loss: 0.08767  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.922  proto_contrastive_loss: 1.838  time: 0.9719  data_time: 0.0075  lr: 0.002  max_mem: 3769M
[12/22 19:34:00] d2.utils.events INFO:  eta: 0:00:38  iter: 59  roi_cover_ratio: 0.8187  cls_acc: 0.9512  fg_cls_acc: 0.988  false_neg_ratio: 0.01205  total_loss: 4.987  aux_bce_loss_0: 0.205  aux_dice_loss_0: 0.139  rg_l1_loss_0: 0.04156  aux_bce_loss_1: 0.1386  aux_dice_loss_1: 0.08739  rg_l1_loss_1: 0.02421  aux_bce_loss_2: 0.09909  aux_dice_loss_2: 0.05968  rg_l1_loss_2: 0.01511  aux_bce_loss_3: 0.07276  aux_dice_loss_3: 0.04505  rg_l1_loss_3: 0.01212  aux_bce_loss_4: 0.05978  aux_dice_loss_4: 0.03931  rg_l1_loss_4: 0.01009  focal_loss_0: 0.05412  focal_loss_1: 0.03585  focal_loss_2: 0.03103  bbox_loss: 0.06903  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.898  proto_contrastive_loss: 1.836  time: 0.9729  data_time: 0.0079  lr: 0.0002  max_mem: 3769M
[12/22 19:34:20] d2.utils.events INFO:  eta: 0:00:19  iter: 79  roi_cover_ratio: 0.8287  cls_acc: 0.9414  fg_cls_acc: 0.9864  false_neg_ratio: 0.0136  total_loss: 4.905  aux_bce_loss_0: 0.2008  aux_dice_loss_0: 0.1373  rg_l1_loss_0: 0.03968  aux_bce_loss_1: 0.1332  aux_dice_loss_1: 0.08214  rg_l1_loss_1: 0.02159  aux_bce_loss_2: 0.09121  aux_dice_loss_2: 0.05641  rg_l1_loss_2: 0.01398  aux_bce_loss_3: 0.06638  aux_dice_loss_3: 0.04195  rg_l1_loss_3: 0.01126  aux_bce_loss_4: 0.05371  aux_dice_loss_4: 0.03664  rg_l1_loss_4: 0.009377  focal_loss_0: 0.04625  focal_loss_1: 0.03308  focal_loss_2: 0.03001  bbox_loss: 0.06564  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.894  proto_contrastive_loss: 1.835  time: 0.9775  data_time: 0.0076  lr: 0.0002  max_mem: 3769M
[12/22 19:34:40] fvcore.common.checkpoint INFO: Saving checkpoint to output/vitb/artaxor_5shot/model_0000099.pth
[12/22 19:34:41] fvcore.common.checkpoint INFO: Saving checkpoint to output/vitb/artaxor_5shot/model_final.pth
[12/22 19:34:41] d2.utils.events INFO:  eta: 0:00:00  iter: 99  roi_cover_ratio: 0.8186  cls_acc: 0.9473  fg_cls_acc: 0.9882  false_neg_ratio: 0.01178  total_loss: 4.879  aux_bce_loss_0: 0.2019  aux_dice_loss_0: 0.1327  rg_l1_loss_0: 0.03836  aux_bce_loss_1: 0.132  aux_dice_loss_1: 0.08047  rg_l1_loss_1: 0.0217  aux_bce_loss_2: 0.09178  aux_dice_loss_2: 0.05439  rg_l1_loss_2: 0.01329  aux_bce_loss_3: 0.06635  aux_dice_loss_3: 0.041  rg_l1_loss_3: 0.01096  aux_bce_loss_4: 0.05439  aux_dice_loss_4: 0.03597  rg_l1_loss_4: 0.009252  focal_loss_0: 0.04497  focal_loss_1: 0.03139  focal_loss_2: 0.02778  bbox_loss: 0.06416  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.892  proto_contrastive_loss: 1.835  time: 0.9775  data_time: 0.0070  lr: 2e-05  max_mem: 3769M
[12/22 19:34:41] d2.engine.hooks INFO: Overall training speed: 98 iterations in 0:01:35 (0.9775 s / it)
[12/22 19:34:41] d2.engine.hooks INFO: Total training time: 0:01:37 (0:00:01 on hooks)
[12/22 19:34:41] d2.data.datasets.coco INFO: Loaded 1383 images in COCO format from datasets/ArTaxOr/annotations/test.json
[12/22 19:34:41] d2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 455          | Coleoptera  | 145          |   Diptera   | 35           |
| Hemiptera  | 474          | Hymenoptera | 60           | Lepidoptera | 136          |
|  Odonata   | 323          |             |              |             |              |
|   total    | 1628         |             |              |             |              |[0m
[12/22 19:34:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/22 19:34:41] d2.data.common INFO: Serializing 1383 elements to byte tensors and concatenating them all ...
[12/22 19:34:41] d2.data.common INFO: Serialized dataset takes 0.40 MiB
[12/22 19:34:41] d2.evaluation.evaluator INFO: Start inference on 346 batches
[12/22 19:35:02] d2.evaluation.evaluator INFO: Inference done 11/346. Dataloading: 0.0012 s / iter. Inference: 0.6956 s / iter. Eval: 0.0003 s / iter. Total: 0.6971 s / iter. ETA=0:03:53
[12/22 19:43:06] detectron2 INFO: Rank of current process: 0. World size: 4
[12/22 19:43:07] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/22 19:43:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/artaxor/vitb_shot5_artaxor_finetune.yaml', resume=False, eval_only=False, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'weights/trained/few-shot/vitb_0089999.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/artaxor_5shot/'])
[12/22 19:43:07] detectron2 INFO: Contents of args.config_file=configs/artaxor/vitb_shot5_artaxor_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/ArTaxOr_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("ArTaxOr_5shot",)
  TEST: ("ArTaxOr_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/22 19:43:07] detectron2 INFO: Full config saved to output/vitb/artaxor_5shot/config.yaml
[12/22 19:43:13] d2.data.datasets.coco INFO: Loaded 35 images in COCO format from datasets/ArTaxOr/annotations/5_shot.json
[12/22 19:43:13] d2.data.build INFO: Removed 0 images with no usable annotations. 35 images left.
[12/22 19:43:13] d2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 5            | Coleoptera  | 5            |   Diptera   | 5            |
| Hemiptera  | 5            | Hymenoptera | 5            | Lepidoptera | 5            |
|  Odonata   | 5            |             |              |             |              |
|   total    | 35           |             |              |             |              |[0m
[12/22 19:43:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[12/22 19:43:13] d2.data.build INFO: Using training sampler TrainingSampler
[12/22 19:43:13] d2.data.common INFO: Serializing 35 elements to byte tensors and concatenating them all ...
[12/22 19:43:13] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[12/22 19:43:13] fvcore.common.checkpoint INFO: [Checkpointer] Loading from weights/trained/few-shot/vitb_0089999.pth ...
[12/22 19:43:14] fvcore.common.checkpoint WARNING: Skip loading parameter 'test_class_weight' to the model due to incompatible shapes: (80, 768) in the checkpoint but (7, 768) in the model! You might want to double check if this is expected.
[12/22 19:43:14] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34madapter.proto_center_attn.attention_weights.0.{bias, weight}[0m
[34madapter.proto_center_attn.fc.{bias, weight}[0m
[34mbg_tokens.weight[0m
[34mclass_weights.weight[0m
[34mdomain_prompter.weight[0m
[34mprototype_classifier.linear.{bias, weight}[0m
[34mtest_class_weight[0m
[12/22 19:43:14] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mtrain_class_weight[0m
[12/22 19:43:14] d2.engine.train_loop INFO: Starting training from iteration 0
[12/22 19:43:40] d2.utils.events INFO:  eta: 0:01:18  iter: 19  roi_cover_ratio: 0.8388  cls_acc: 0.8545  fg_cls_acc: 0.9002  false_neg_ratio: 0.04869  total_loss: 6.107  aux_bce_loss_0: 0.2936  aux_dice_loss_0: 0.1832  rg_l1_loss_0: 0.05509  aux_bce_loss_1: 0.2342  aux_dice_loss_1: 0.1416  rg_l1_loss_1: 0.0393  aux_bce_loss_2: 0.1774  aux_dice_loss_2: 0.1029  rg_l1_loss_2: 0.02656  aux_bce_loss_3: 0.1364  aux_dice_loss_3: 0.08061  rg_l1_loss_3: 0.02203  aux_bce_loss_4: 0.1201  aux_dice_loss_4: 0.07249  rg_l1_loss_4: 0.01904  focal_loss_0: 0.227  focal_loss_1: 0.1404  focal_loss_2: 0.1152  bbox_loss: 0.1256  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.942  proto_contrastive_loss: 1.84  time: 0.9727  data_time: 0.2950  lr: 0.0019001  max_mem: 3630M
[12/22 19:43:59] d2.utils.events INFO:  eta: 0:00:58  iter: 39  roi_cover_ratio: 0.83  cls_acc: 0.918  fg_cls_acc: 0.975  false_neg_ratio: 0.02502  total_loss: 5.284  aux_bce_loss_0: 0.2427  aux_dice_loss_0: 0.153  rg_l1_loss_0: 0.04669  aux_bce_loss_1: 0.1673  aux_dice_loss_1: 0.1001  rg_l1_loss_1: 0.02884  aux_bce_loss_2: 0.1193  aux_dice_loss_2: 0.07091  rg_l1_loss_2: 0.01966  aux_bce_loss_3: 0.08944  aux_dice_loss_3: 0.0549  rg_l1_loss_3: 0.0149  aux_bce_loss_4: 0.07233  aux_dice_loss_4: 0.04893  rg_l1_loss_4: 0.0122  focal_loss_0: 0.0955  focal_loss_1: 0.05262  focal_loss_2: 0.04399  bbox_loss: 0.08793  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.922  proto_contrastive_loss: 1.838  time: 0.9751  data_time: 0.0071  lr: 0.002  max_mem: 3769M
[12/22 19:44:19] d2.utils.events INFO:  eta: 0:00:39  iter: 59  roi_cover_ratio: 0.8187  cls_acc: 0.9531  fg_cls_acc: 0.9869  false_neg_ratio: 0.01314  total_loss: 4.988  aux_bce_loss_0: 0.2052  aux_dice_loss_0: 0.1391  rg_l1_loss_0: 0.04156  aux_bce_loss_1: 0.1386  aux_dice_loss_1: 0.08747  rg_l1_loss_1: 0.0243  aux_bce_loss_2: 0.09927  aux_dice_loss_2: 0.05974  rg_l1_loss_2: 0.01513  aux_bce_loss_3: 0.07287  aux_dice_loss_3: 0.04508  rg_l1_loss_3: 0.0121  aux_bce_loss_4: 0.05975  aux_dice_loss_4: 0.03933  rg_l1_loss_4: 0.01012  focal_loss_0: 0.05357  focal_loss_1: 0.03599  focal_loss_2: 0.03057  bbox_loss: 0.06891  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.898  proto_contrastive_loss: 1.836  time: 0.9804  data_time: 0.0067  lr: 0.0002  max_mem: 3769M
[12/22 19:44:39] d2.utils.events INFO:  eta: 0:00:19  iter: 79  roi_cover_ratio: 0.8287  cls_acc: 0.9414  fg_cls_acc: 0.9834  false_neg_ratio: 0.01661  total_loss: 4.905  aux_bce_loss_0: 0.2011  aux_dice_loss_0: 0.1374  rg_l1_loss_0: 0.03965  aux_bce_loss_1: 0.1334  aux_dice_loss_1: 0.0822  rg_l1_loss_1: 0.02159  aux_bce_loss_2: 0.09136  aux_dice_loss_2: 0.05645  rg_l1_loss_2: 0.01401  aux_bce_loss_3: 0.06631  aux_dice_loss_3: 0.04194  rg_l1_loss_3: 0.01128  aux_bce_loss_4: 0.05364  aux_dice_loss_4: 0.03671  rg_l1_loss_4: 0.009357  focal_loss_0: 0.04571  focal_loss_1: 0.03318  focal_loss_2: 0.02983  bbox_loss: 0.06561  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.894  proto_contrastive_loss: 1.835  time: 0.9796  data_time: 0.0069  lr: 0.0002  max_mem: 3769M
[12/22 19:44:58] fvcore.common.checkpoint INFO: Saving checkpoint to output/vitb/artaxor_5shot/model_0000099.pth
[12/22 19:45:02] fvcore.common.checkpoint INFO: Saving checkpoint to output/vitb/artaxor_5shot/model_final.pth
[12/22 19:45:06] d2.utils.events INFO:  eta: 0:00:00  iter: 99  roi_cover_ratio: 0.8186  cls_acc: 0.9473  fg_cls_acc: 0.9875  false_neg_ratio: 0.01251  total_loss: 4.879  aux_bce_loss_0: 0.2019  aux_dice_loss_0: 0.1328  rg_l1_loss_0: 0.03836  aux_bce_loss_1: 0.1322  aux_dice_loss_1: 0.08056  rg_l1_loss_1: 0.0217  aux_bce_loss_2: 0.09194  aux_dice_loss_2: 0.05442  rg_l1_loss_2: 0.0133  aux_bce_loss_3: 0.06635  aux_dice_loss_3: 0.04104  rg_l1_loss_3: 0.011  aux_bce_loss_4: 0.05437  aux_dice_loss_4: 0.036  rg_l1_loss_4: 0.009242  focal_loss_0: 0.04452  focal_loss_1: 0.03113  focal_loss_2: 0.02765  bbox_loss: 0.06405  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.892  proto_contrastive_loss: 1.835  time: 0.9799  data_time: 0.0070  lr: 2e-05  max_mem: 3769M
[12/22 19:45:06] d2.engine.hooks INFO: Overall training speed: 98 iterations in 0:01:36 (0.9799 s / it)
[12/22 19:45:06] d2.engine.hooks INFO: Total training time: 0:01:43 (0:00:07 on hooks)
[12/22 19:45:06] d2.data.datasets.coco INFO: Loaded 1383 images in COCO format from datasets/ArTaxOr/annotations/test.json
[12/22 19:45:06] d2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 455          | Coleoptera  | 145          |   Diptera   | 35           |
| Hemiptera  | 474          | Hymenoptera | 60           | Lepidoptera | 136          |
|  Odonata   | 323          |             |              |             |              |
|   total    | 1628         |             |              |             |              |[0m
[12/22 19:45:06] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/22 19:45:06] d2.data.common INFO: Serializing 1383 elements to byte tensors and concatenating them all ...
[12/22 19:45:06] d2.data.common INFO: Serialized dataset takes 0.40 MiB
[12/22 19:45:06] d2.evaluation.evaluator INFO: Start inference on 346 batches
[12/22 21:42:41] detectron2 INFO: Rank of current process: 0. World size: 4
[12/22 21:42:42] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/22 21:42:42] detectron2 INFO: Command line arguments: Namespace(config_file='configs/artaxor/vitb_shot5_artaxor_finetune.yaml', resume=False, eval_only=False, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'weights/trained/few-shot/vitb_0089999.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/artaxor_5shot/'])
[12/22 21:42:42] detectron2 INFO: Contents of args.config_file=configs/artaxor/vitb_shot5_artaxor_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/ArTaxOr_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("ArTaxOr_5shot",)
  TEST: ("ArTaxOr_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/22 21:42:42] detectron2 INFO: Full config saved to output/vitb/artaxor_5shot/config.yaml
[12/22 21:42:47] d2.data.datasets.coco INFO: Loaded 35 images in COCO format from datasets/ArTaxOr/annotations/5_shot.json
[12/22 21:42:47] d2.data.build INFO: Removed 0 images with no usable annotations. 35 images left.
[12/22 21:42:47] d2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 5            | Coleoptera  | 5            |   Diptera   | 5            |
| Hemiptera  | 5            | Hymenoptera | 5            | Lepidoptera | 5            |
|  Odonata   | 5            |             |              |             |              |
|   total    | 35           |             |              |             |              |[0m
[12/22 21:42:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[12/22 21:42:47] d2.data.build INFO: Using training sampler TrainingSampler
[12/22 21:42:48] d2.data.common INFO: Serializing 35 elements to byte tensors and concatenating them all ...
[12/22 21:42:48] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[12/22 21:42:48] fvcore.common.checkpoint INFO: [Checkpointer] Loading from weights/trained/few-shot/vitb_0089999.pth ...
[12/22 21:42:49] fvcore.common.checkpoint WARNING: Skip loading parameter 'test_class_weight' to the model due to incompatible shapes: (80, 768) in the checkpoint but (7, 768) in the model! You might want to double check if this is expected.
[12/22 21:42:49] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34madapter.proto_center_attn.attention_weights.0.{bias, weight}[0m
[34madapter.proto_center_attn.fc.{bias, weight}[0m
[34mbg_tokens.weight[0m
[34mclass_weights.weight[0m
[34mdomain_prompter.weight[0m
[34mprototype_classifier.linear.{bias, weight}[0m
[34mtest_class_weight[0m
[12/22 21:42:49] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mtrain_class_weight[0m
[12/22 21:42:49] d2.engine.train_loop INFO: Starting training from iteration 0
[12/22 21:43:16] d2.utils.events INFO:  eta: 0:01:17  iter: 19  roi_cover_ratio: 0.8388  cls_acc: 0.8545  fg_cls_acc: 0.9124  false_neg_ratio: 0.04406  total_loss: 6.108  aux_bce_loss_0: 0.2937  aux_dice_loss_0: 0.1832  rg_l1_loss_0: 0.05514  aux_bce_loss_1: 0.2344  aux_dice_loss_1: 0.1416  rg_l1_loss_1: 0.03923  aux_bce_loss_2: 0.1775  aux_dice_loss_2: 0.1029  rg_l1_loss_2: 0.02654  aux_bce_loss_3: 0.1363  aux_dice_loss_3: 0.08066  rg_l1_loss_3: 0.02203  aux_bce_loss_4: 0.12  aux_dice_loss_4: 0.07241  rg_l1_loss_4: 0.01905  focal_loss_0: 0.2268  focal_loss_1: 0.1396  focal_loss_2: 0.1151  bbox_loss: 0.1256  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.942  proto_contrastive_loss: 1.84  time: 0.9676  data_time: 0.3600  lr: 0.0019001  max_mem: 3630M
[12/22 21:43:35] d2.utils.events INFO:  eta: 0:00:57  iter: 39  roi_cover_ratio: 0.83  cls_acc: 0.916  fg_cls_acc: 0.975  false_neg_ratio: 0.02502  total_loss: 5.288  aux_bce_loss_0: 0.2424  aux_dice_loss_0: 0.1527  rg_l1_loss_0: 0.04664  aux_bce_loss_1: 0.167  aux_dice_loss_1: 0.09996  rg_l1_loss_1: 0.02874  aux_bce_loss_2: 0.1191  aux_dice_loss_2: 0.07082  rg_l1_loss_2: 0.0196  aux_bce_loss_3: 0.08952  aux_dice_loss_3: 0.05479  rg_l1_loss_3: 0.01489  aux_bce_loss_4: 0.07232  aux_dice_loss_4: 0.04884  rg_l1_loss_4: 0.01222  focal_loss_0: 0.0957  focal_loss_1: 0.05349  focal_loss_2: 0.04536  bbox_loss: 0.08791  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.922  proto_contrastive_loss: 1.838  time: 0.9695  data_time: 0.0075  lr: 0.002  max_mem: 3769M
[12/22 21:43:55] d2.utils.events INFO:  eta: 0:00:38  iter: 59  roi_cover_ratio: 0.8187  cls_acc: 0.9512  fg_cls_acc: 0.9874  false_neg_ratio: 0.01191  total_loss: 4.986  aux_bce_loss_0: 0.2048  aux_dice_loss_0: 0.1389  rg_l1_loss_0: 0.04163  aux_bce_loss_1: 0.1387  aux_dice_loss_1: 0.08734  rg_l1_loss_1: 0.02422  aux_bce_loss_2: 0.09909  aux_dice_loss_2: 0.05966  rg_l1_loss_2: 0.0151  aux_bce_loss_3: 0.07278  aux_dice_loss_3: 0.04506  rg_l1_loss_3: 0.01212  aux_bce_loss_4: 0.0598  aux_dice_loss_4: 0.03935  rg_l1_loss_4: 0.01012  focal_loss_0: 0.05522  focal_loss_1: 0.03599  focal_loss_2: 0.03147  bbox_loss: 0.06893  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.898  proto_contrastive_loss: 1.836  time: 0.9742  data_time: 0.0070  lr: 0.0002  max_mem: 3769M
[12/22 21:44:14] d2.utils.events INFO:  eta: 0:00:19  iter: 79  roi_cover_ratio: 0.8287  cls_acc: 0.9414  fg_cls_acc: 0.9813  false_neg_ratio: 0.01869  total_loss: 4.904  aux_bce_loss_0: 0.2008  aux_dice_loss_0: 0.1371  rg_l1_loss_0: 0.03962  aux_bce_loss_1: 0.1332  aux_dice_loss_1: 0.08202  rg_l1_loss_1: 0.02154  aux_bce_loss_2: 0.09126  aux_dice_loss_2: 0.05636  rg_l1_loss_2: 0.014  aux_bce_loss_3: 0.06628  aux_dice_loss_3: 0.04192  rg_l1_loss_3: 0.01125  aux_bce_loss_4: 0.05361  aux_dice_loss_4: 0.03665  rg_l1_loss_4: 0.009368  focal_loss_0: 0.04618  focal_loss_1: 0.03299  focal_loss_2: 0.03005  bbox_loss: 0.06543  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.894  proto_contrastive_loss: 1.835  time: 0.9732  data_time: 0.0072  lr: 0.0002  max_mem: 3769M
[12/22 21:44:34] fvcore.common.checkpoint INFO: Saving checkpoint to output/vitb/artaxor_5shot/model_0000099.pth
[12/22 21:44:37] fvcore.common.checkpoint INFO: Saving checkpoint to output/vitb/artaxor_5shot/model_final.pth
[12/22 21:44:40] d2.utils.events INFO:  eta: 0:00:00  iter: 99  roi_cover_ratio: 0.8186  cls_acc: 0.9473  fg_cls_acc: 0.9875  false_neg_ratio: 0.01251  total_loss: 4.878  aux_bce_loss_0: 0.2015  aux_dice_loss_0: 0.1325  rg_l1_loss_0: 0.03837  aux_bce_loss_1: 0.1319  aux_dice_loss_1: 0.08035  rg_l1_loss_1: 0.0216  aux_bce_loss_2: 0.09175  aux_dice_loss_2: 0.05433  rg_l1_loss_2: 0.01327  aux_bce_loss_3: 0.06624  aux_dice_loss_3: 0.04097  rg_l1_loss_3: 0.01099  aux_bce_loss_4: 0.05429  aux_dice_loss_4: 0.03599  rg_l1_loss_4: 0.009232  focal_loss_0: 0.04484  focal_loss_1: 0.03139  focal_loss_2: 0.02783  bbox_loss: 0.06408  domain_prompter_contrasitive_loss: 0.0006493  prototype_cls_loss: 1.892  proto_contrastive_loss: 1.835  time: 0.9735  data_time: 0.0067  lr: 2e-05  max_mem: 3769M
[12/22 21:44:40] d2.engine.hooks INFO: Overall training speed: 98 iterations in 0:01:35 (0.9735 s / it)
[12/22 21:44:40] d2.engine.hooks INFO: Total training time: 0:01:41 (0:00:05 on hooks)
[12/22 21:44:40] d2.data.datasets.coco INFO: Loaded 1383 images in COCO format from datasets/ArTaxOr/annotations/test.json
[12/22 21:44:40] d2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 455          | Coleoptera  | 145          |   Diptera   | 35           |
| Hemiptera  | 474          | Hymenoptera | 60           | Lepidoptera | 136          |
|  Odonata   | 323          |             |              |             |              |
|   total    | 1628         |             |              |             |              |[0m
[12/22 21:44:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/22 21:44:40] d2.data.common INFO: Serializing 1383 elements to byte tensors and concatenating them all ...
[12/22 21:44:40] d2.data.common INFO: Serialized dataset takes 0.40 MiB
[12/22 21:44:40] d2.evaluation.evaluator INFO: Start inference on 346 batches
[12/23 16:19:53] detectron2 INFO: Rank of current process: 0. World size: 1
[12/23 16:19:54] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/23 16:19:54] detectron2 INFO: Command line arguments: Namespace(config_file='configs/artaxor/vitb_shot5_artaxor_finetune.yaml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/artaxor_5shot/model_final.pth', 'OUTPUT_DIR', 'output/vitb/artaxor_5shot/'])
[12/23 16:19:54] detectron2 INFO: Contents of args.config_file=configs/artaxor/vitb_shot5_artaxor_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/ArTaxOr_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("ArTaxOr_5shot",)
  TEST: ("ArTaxOr_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 16:19:54] detectron2 INFO: Full config saved to output/vitb/artaxor_5shot/config.yaml
[12/23 16:29:59] detectron2 INFO: Rank of current process: 0. World size: 1
[12/23 16:30:00] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/23 16:30:00] detectron2 INFO: Command line arguments: Namespace(config_file='configs/artaxor/vitb_shot5_artaxor_finetune.yaml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/artaxor_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/artaxor_5shot/'])
[12/23 16:30:00] detectron2 INFO: Contents of args.config_file=configs/artaxor/vitb_shot5_artaxor_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/ArTaxOr_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("ArTaxOr_5shot",)
  TEST: ("ArTaxOr_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 16:30:00] detectron2 INFO: Full config saved to output/vitb/artaxor_5shot/config.yaml
[12/23 16:30:05] fvcore.common.checkpoint INFO: [Checkpointer] Loading from output/vitb/artaxor_5shot/model_final.pth ...
[12/23 16:30:06] d2.data.datasets.coco INFO: Loaded 1383 images in COCO format from datasets/ArTaxOr/annotations/test.json
[12/23 16:30:06] d2.data.build INFO: Distribution of instances among all 7 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 455          | Coleoptera  | 145          |   Diptera   | 35           |
| Hemiptera  | 474          | Hymenoptera | 60           | Lepidoptera | 136          |
|  Odonata   | 323          |             |              |             |              |
|   total    | 1628         |             |              |             |              |
[12/23 16:30:06] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/23 16:30:06] d2.data.common INFO: Serializing 1383 elements to byte tensors and concatenating them all ...
[12/23 16:30:06] d2.data.common INFO: Serialized dataset takes 0.40 MiB
[12/23 16:30:06] d2.evaluation.evaluator INFO: Start inference on 1383 batches
[12/23 16:30:15] d2.evaluation.evaluator INFO: Inference done 11/1383. Dataloading: 0.0016 s / iter. Inference: 0.7345 s / iter. Eval: 0.0003 s / iter. Total: 0.7364 s / iter. ETA=0:16:50
[12/23 16:30:21] d2.evaluation.evaluator INFO: Inference done 21/1383. Dataloading: 0.0020 s / iter. Inference: 0.6077 s / iter. Eval: 0.0003 s / iter. Total: 0.6101 s / iter. ETA=0:13:50
[12/23 16:30:26] d2.evaluation.evaluator INFO: Inference done 31/1383. Dataloading: 0.0020 s / iter. Inference: 0.5902 s / iter. Eval: 0.0003 s / iter. Total: 0.5926 s / iter. ETA=0:13:21
[12/23 18:24:30] detectron2 INFO: Rank of current process: 0. World size: 1
[12/23 18:24:31] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/23 18:24:31] detectron2 INFO: Command line arguments: Namespace(config_file='configs/artaxor/vitb_shot5_artaxor_finetune.yaml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/artaxor_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/artaxor_5shot/'])
[12/23 18:24:31] detectron2 INFO: Contents of args.config_file=configs/artaxor/vitb_shot5_artaxor_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/ArTaxOr_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("ArTaxOr_5shot",)
  TEST: ("ArTaxOr_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 18:24:31] detectron2 INFO: Full config saved to output/vitb/artaxor_5shot/config.yaml
[12/23 18:24:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from output/vitb/artaxor_5shot/model_final.pth ...
[12/23 18:24:37] d2.data.datasets.coco INFO: Loaded 1383 images in COCO format from datasets/ArTaxOr/annotations/test.json
[12/23 18:24:37] d2.data.build INFO: Distribution of instances among all 7 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 455          | Coleoptera  | 145          |   Diptera   | 35           |
| Hemiptera  | 474          | Hymenoptera | 60           | Lepidoptera | 136          |
|  Odonata   | 323          |             |              |             |              |
|   total    | 1628         |             |              |             |              |
[12/23 18:24:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/23 18:24:37] d2.data.common INFO: Serializing 1383 elements to byte tensors and concatenating them all ...
[12/23 18:24:37] d2.data.common INFO: Serialized dataset takes 0.40 MiB
[12/23 18:24:37] d2.evaluation.evaluator INFO: Start inference on 1383 batches
[12/23 18:24:46] d2.evaluation.evaluator INFO: Inference done 11/1383. Dataloading: 0.0014 s / iter. Inference: 0.7380 s / iter. Eval: 0.0003 s / iter. Total: 0.7398 s / iter. ETA=0:16:54
[12/23 18:24:52] d2.evaluation.evaluator INFO: Inference done 21/1383. Dataloading: 0.0017 s / iter. Inference: 0.6107 s / iter. Eval: 0.0003 s / iter. Total: 0.6128 s / iter. ETA=0:13:54
[12/23 18:24:57] d2.evaluation.evaluator INFO: Inference done 31/1383. Dataloading: 0.0018 s / iter. Inference: 0.5933 s / iter. Eval: 0.0003 s / iter. Total: 0.5954 s / iter. ETA=0:13:25
[12/23 19:02:36] detectron2 INFO: Rank of current process: 0. World size: 4
[12/23 19:02:37] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/23 19:02:37] detectron2 INFO: Command line arguments: Namespace(config_file='configs/artaxor/vitb_shot5_artaxor_finetune.yaml', resume=False, eval_only=True, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/artaxor_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/artaxor_5shot/', 'SOLVER.IMS_PER_BATCH', '4'])
[12/23 19:02:37] detectron2 INFO: Contents of args.config_file=configs/artaxor/vitb_shot5_artaxor_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/ArTaxOr_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("ArTaxOr_5shot",)
  TEST: ("ArTaxOr_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 19:02:37] detectron2 INFO: Full config saved to output/vitb/artaxor_5shot/config.yaml
[12/23 19:02:42] fvcore.common.checkpoint INFO: [Checkpointer] Loading from output/vitb/artaxor_5shot/model_final.pth ...
[12/23 19:02:43] d2.data.datasets.coco INFO: Loaded 1383 images in COCO format from datasets/ArTaxOr/annotations/test.json
[12/23 19:02:43] d2.data.build INFO: Distribution of instances among all 7 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 455          | Coleoptera  | 145          |   Diptera   | 35           |
| Hemiptera  | 474          | Hymenoptera | 60           | Lepidoptera | 136          |
|  Odonata   | 323          |             |              |             |              |
|   total    | 1628         |             |              |             |              |
[12/23 19:02:43] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/23 19:02:43] d2.data.common INFO: Serializing 1383 elements to byte tensors and concatenating them all ...
[12/23 19:02:43] d2.data.common INFO: Serialized dataset takes 0.40 MiB
[12/23 19:02:43] d2.evaluation.evaluator INFO: Start inference on 346 batches
[12/23 19:03:18] d2.evaluation.evaluator INFO: Inference done 11/346. Dataloading: 0.0013 s / iter. Inference: 1.4191 s / iter. Eval: 0.0003 s / iter. Total: 1.4208 s / iter. ETA=0:07:55
[12/23 19:03:24] d2.evaluation.evaluator INFO: Inference done 16/346. Dataloading: 0.0015 s / iter. Inference: 1.3523 s / iter. Eval: 0.0004 s / iter. Total: 1.3542 s / iter. ETA=0:07:26
[12/23 19:03:30] d2.evaluation.evaluator INFO: Inference done 22/346. Dataloading: 0.0017 s / iter. Inference: 1.2081 s / iter. Eval: 0.0003 s / iter. Total: 1.2102 s / iter. ETA=0:06:32
[12/23 19:03:35] d2.evaluation.evaluator INFO: Inference done 27/346. Dataloading: 0.0018 s / iter. Inference: 1.1997 s / iter. Eval: 0.0004 s / iter. Total: 1.2020 s / iter. ETA=0:06:23
[12/23 19:03:42] d2.evaluation.evaluator INFO: Inference done 32/346. Dataloading: 0.0018 s / iter. Inference: 1.2107 s / iter. Eval: 0.0003 s / iter. Total: 1.2131 s / iter. ETA=0:06:20
[12/23 19:03:47] d2.evaluation.evaluator INFO: Inference done 36/346. Dataloading: 0.0019 s / iter. Inference: 1.2219 s / iter. Eval: 0.0003 s / iter. Total: 1.2242 s / iter. ETA=0:06:19
[12/23 19:03:53] d2.evaluation.evaluator INFO: Inference done 40/346. Dataloading: 0.0018 s / iter. Inference: 1.2657 s / iter. Eval: 0.0003 s / iter. Total: 1.2680 s / iter. ETA=0:06:28
[12/23 19:03:59] d2.evaluation.evaluator INFO: Inference done 44/346. Dataloading: 0.0019 s / iter. Inference: 1.2730 s / iter. Eval: 0.0003 s / iter. Total: 1.2753 s / iter. ETA=0:06:25
[12/23 19:04:05] d2.evaluation.evaluator INFO: Inference done 47/346. Dataloading: 0.0019 s / iter. Inference: 1.3195 s / iter. Eval: 0.0003 s / iter. Total: 1.3218 s / iter. ETA=0:06:35
[12/23 19:04:10] d2.evaluation.evaluator INFO: Inference done 51/346. Dataloading: 0.0018 s / iter. Inference: 1.3269 s / iter. Eval: 0.0003 s / iter. Total: 1.3292 s / iter. ETA=0:06:32
[12/23 19:04:15] d2.evaluation.evaluator INFO: Inference done 56/346. Dataloading: 0.0018 s / iter. Inference: 1.2986 s / iter. Eval: 0.0003 s / iter. Total: 1.3009 s / iter. ETA=0:06:17
[12/23 19:04:21] d2.evaluation.evaluator INFO: Inference done 61/346. Dataloading: 0.0018 s / iter. Inference: 1.2842 s / iter. Eval: 0.0003 s / iter. Total: 1.2865 s / iter. ETA=0:06:06
[12/23 19:04:27] d2.evaluation.evaluator INFO: Inference done 64/346. Dataloading: 0.0018 s / iter. Inference: 1.3242 s / iter. Eval: 0.0003 s / iter. Total: 1.3264 s / iter. ETA=0:06:14
[12/23 19:04:34] d2.evaluation.evaluator INFO: Inference done 68/346. Dataloading: 0.0018 s / iter. Inference: 1.3508 s / iter. Eval: 0.0003 s / iter. Total: 1.3530 s / iter. ETA=0:06:16
[12/23 19:04:40] d2.evaluation.evaluator INFO: Inference done 73/346. Dataloading: 0.0018 s / iter. Inference: 1.3356 s / iter. Eval: 0.0003 s / iter. Total: 1.3378 s / iter. ETA=0:06:05
[12/23 19:04:45] d2.evaluation.evaluator INFO: Inference done 76/346. Dataloading: 0.0018 s / iter. Inference: 1.3538 s / iter. Eval: 0.0003 s / iter. Total: 1.3561 s / iter. ETA=0:06:06
[12/23 19:04:51] d2.evaluation.evaluator INFO: Inference done 81/346. Dataloading: 0.0018 s / iter. Inference: 1.3385 s / iter. Eval: 0.0003 s / iter. Total: 1.3407 s / iter. ETA=0:05:55
[12/23 19:04:56] d2.evaluation.evaluator INFO: Inference done 85/346. Dataloading: 0.0018 s / iter. Inference: 1.3408 s / iter. Eval: 0.0003 s / iter. Total: 1.3431 s / iter. ETA=0:05:50
[12/23 19:05:02] d2.evaluation.evaluator INFO: Inference done 89/346. Dataloading: 0.0018 s / iter. Inference: 1.3376 s / iter. Eval: 0.0003 s / iter. Total: 1.3398 s / iter. ETA=0:05:44
[12/23 19:05:08] d2.evaluation.evaluator INFO: Inference done 94/346. Dataloading: 0.0018 s / iter. Inference: 1.3307 s / iter. Eval: 0.0003 s / iter. Total: 1.3330 s / iter. ETA=0:05:35
[12/23 19:05:13] d2.evaluation.evaluator INFO: Inference done 99/346. Dataloading: 0.0018 s / iter. Inference: 1.3218 s / iter. Eval: 0.0003 s / iter. Total: 1.3241 s / iter. ETA=0:05:27
[12/23 19:05:19] d2.evaluation.evaluator INFO: Inference done 101/346. Dataloading: 0.0018 s / iter. Inference: 1.3504 s / iter. Eval: 0.0003 s / iter. Total: 1.3526 s / iter. ETA=0:05:31
[12/23 19:05:24] d2.evaluation.evaluator INFO: Inference done 104/346. Dataloading: 0.0018 s / iter. Inference: 1.3610 s / iter. Eval: 0.0003 s / iter. Total: 1.3632 s / iter. ETA=0:05:29
[12/23 19:05:29] d2.evaluation.evaluator INFO: Inference done 108/346. Dataloading: 0.0018 s / iter. Inference: 1.3606 s / iter. Eval: 0.0003 s / iter. Total: 1.3629 s / iter. ETA=0:05:24
[12/23 19:05:35] d2.evaluation.evaluator INFO: Inference done 113/346. Dataloading: 0.0018 s / iter. Inference: 1.3514 s / iter. Eval: 0.0003 s / iter. Total: 1.3536 s / iter. ETA=0:05:15
[12/23 19:05:40] d2.evaluation.evaluator INFO: Inference done 116/346. Dataloading: 0.0018 s / iter. Inference: 1.3606 s / iter. Eval: 0.0003 s / iter. Total: 1.3628 s / iter. ETA=0:05:13
[12/23 19:05:46] d2.evaluation.evaluator INFO: Inference done 121/346. Dataloading: 0.0018 s / iter. Inference: 1.3479 s / iter. Eval: 0.0003 s / iter. Total: 1.3502 s / iter. ETA=0:05:03
[12/23 19:05:51] d2.evaluation.evaluator INFO: Inference done 126/346. Dataloading: 0.0018 s / iter. Inference: 1.3381 s / iter. Eval: 0.0003 s / iter. Total: 1.3403 s / iter. ETA=0:04:54
[12/23 19:05:57] d2.evaluation.evaluator INFO: Inference done 130/346. Dataloading: 0.0017 s / iter. Inference: 1.3381 s / iter. Eval: 0.0003 s / iter. Total: 1.3403 s / iter. ETA=0:04:49
[12/23 19:06:03] d2.evaluation.evaluator INFO: Inference done 135/346. Dataloading: 0.0017 s / iter. Inference: 1.3394 s / iter. Eval: 0.0003 s / iter. Total: 1.3416 s / iter. ETA=0:04:43
[12/23 19:06:10] d2.evaluation.evaluator INFO: Inference done 139/346. Dataloading: 0.0017 s / iter. Inference: 1.3502 s / iter. Eval: 0.0003 s / iter. Total: 1.3524 s / iter. ETA=0:04:39
[12/23 19:06:16] d2.evaluation.evaluator INFO: Inference done 143/346. Dataloading: 0.0017 s / iter. Inference: 1.3542 s / iter. Eval: 0.0003 s / iter. Total: 1.3563 s / iter. ETA=0:04:35
[12/23 19:06:22] d2.evaluation.evaluator INFO: Inference done 147/346. Dataloading: 0.0017 s / iter. Inference: 1.3562 s / iter. Eval: 0.0003 s / iter. Total: 1.3583 s / iter. ETA=0:04:30
[12/23 19:06:29] d2.evaluation.evaluator INFO: Inference done 152/346. Dataloading: 0.0017 s / iter. Inference: 1.3614 s / iter. Eval: 0.0003 s / iter. Total: 1.3636 s / iter. ETA=0:04:24
[12/23 19:06:35] d2.evaluation.evaluator INFO: Inference done 156/346. Dataloading: 0.0017 s / iter. Inference: 1.3589 s / iter. Eval: 0.0003 s / iter. Total: 1.3610 s / iter. ETA=0:04:18
[12/23 19:06:40] d2.evaluation.evaluator INFO: Inference done 160/346. Dataloading: 0.0017 s / iter. Inference: 1.3619 s / iter. Eval: 0.0003 s / iter. Total: 1.3641 s / iter. ETA=0:04:13
[12/23 19:06:47] d2.evaluation.evaluator INFO: Inference done 166/346. Dataloading: 0.0017 s / iter. Inference: 1.3515 s / iter. Eval: 0.0003 s / iter. Total: 1.3537 s / iter. ETA=0:04:03
[12/23 19:06:54] d2.evaluation.evaluator INFO: Inference done 170/346. Dataloading: 0.0017 s / iter. Inference: 1.3615 s / iter. Eval: 0.0003 s / iter. Total: 1.3636 s / iter. ETA=0:03:59
[12/23 19:07:00] d2.evaluation.evaluator INFO: Inference done 174/346. Dataloading: 0.0017 s / iter. Inference: 1.3637 s / iter. Eval: 0.0003 s / iter. Total: 1.3658 s / iter. ETA=0:03:54
[12/23 19:07:06] d2.evaluation.evaluator INFO: Inference done 178/346. Dataloading: 0.0017 s / iter. Inference: 1.3660 s / iter. Eval: 0.0003 s / iter. Total: 1.3681 s / iter. ETA=0:03:49
[12/23 19:07:12] d2.evaluation.evaluator INFO: Inference done 182/346. Dataloading: 0.0017 s / iter. Inference: 1.3705 s / iter. Eval: 0.0003 s / iter. Total: 1.3726 s / iter. ETA=0:03:45
[12/23 19:07:19] d2.evaluation.evaluator INFO: Inference done 186/346. Dataloading: 0.0017 s / iter. Inference: 1.3769 s / iter. Eval: 0.0003 s / iter. Total: 1.3790 s / iter. ETA=0:03:40
[12/23 19:07:24] d2.evaluation.evaluator INFO: Inference done 191/346. Dataloading: 0.0017 s / iter. Inference: 1.3710 s / iter. Eval: 0.0003 s / iter. Total: 1.3732 s / iter. ETA=0:03:32
[12/23 19:07:31] d2.evaluation.evaluator INFO: Inference done 195/346. Dataloading: 0.0017 s / iter. Inference: 1.3755 s / iter. Eval: 0.0003 s / iter. Total: 1.3777 s / iter. ETA=0:03:28
[12/23 19:07:36] d2.evaluation.evaluator INFO: Inference done 200/346. Dataloading: 0.0017 s / iter. Inference: 1.3694 s / iter. Eval: 0.0003 s / iter. Total: 1.3715 s / iter. ETA=0:03:20
[12/23 19:07:42] d2.evaluation.evaluator INFO: Inference done 203/346. Dataloading: 0.0017 s / iter. Inference: 1.3765 s / iter. Eval: 0.0003 s / iter. Total: 1.3787 s / iter. ETA=0:03:17
[12/23 19:07:47] d2.evaluation.evaluator INFO: Inference done 207/346. Dataloading: 0.0017 s / iter. Inference: 1.3758 s / iter. Eval: 0.0003 s / iter. Total: 1.3780 s / iter. ETA=0:03:11
[12/23 19:07:54] d2.evaluation.evaluator INFO: Inference done 212/346. Dataloading: 0.0017 s / iter. Inference: 1.3723 s / iter. Eval: 0.0003 s / iter. Total: 1.3745 s / iter. ETA=0:03:04
[12/23 19:08:00] d2.evaluation.evaluator INFO: Inference done 217/346. Dataloading: 0.0017 s / iter. Inference: 1.3706 s / iter. Eval: 0.0003 s / iter. Total: 1.3728 s / iter. ETA=0:02:57
[12/23 19:08:05] d2.evaluation.evaluator INFO: Inference done 221/346. Dataloading: 0.0017 s / iter. Inference: 1.3685 s / iter. Eval: 0.0003 s / iter. Total: 1.3707 s / iter. ETA=0:02:51
[12/23 19:08:10] d2.evaluation.evaluator INFO: Inference done 225/346. Dataloading: 0.0017 s / iter. Inference: 1.3670 s / iter. Eval: 0.0003 s / iter. Total: 1.3692 s / iter. ETA=0:02:45
[12/23 19:08:16] d2.evaluation.evaluator INFO: Inference done 229/346. Dataloading: 0.0017 s / iter. Inference: 1.3703 s / iter. Eval: 0.0003 s / iter. Total: 1.3725 s / iter. ETA=0:02:40
[12/23 19:08:23] d2.evaluation.evaluator INFO: Inference done 234/346. Dataloading: 0.0017 s / iter. Inference: 1.3685 s / iter. Eval: 0.0003 s / iter. Total: 1.3706 s / iter. ETA=0:02:33
[12/23 19:08:29] d2.evaluation.evaluator INFO: Inference done 239/346. Dataloading: 0.0017 s / iter. Inference: 1.3655 s / iter. Eval: 0.0003 s / iter. Total: 1.3677 s / iter. ETA=0:02:26
[12/23 19:08:35] d2.evaluation.evaluator INFO: Inference done 244/346. Dataloading: 0.0017 s / iter. Inference: 1.3622 s / iter. Eval: 0.0003 s / iter. Total: 1.3643 s / iter. ETA=0:02:19
[12/23 19:08:40] d2.evaluation.evaluator INFO: Inference done 249/346. Dataloading: 0.0017 s / iter. Inference: 1.3556 s / iter. Eval: 0.0003 s / iter. Total: 1.3577 s / iter. ETA=0:02:11
[12/23 19:08:48] d2.evaluation.evaluator INFO: Inference done 254/346. Dataloading: 0.0017 s / iter. Inference: 1.3596 s / iter. Eval: 0.0003 s / iter. Total: 1.3617 s / iter. ETA=0:02:05
[12/23 19:08:53] d2.evaluation.evaluator INFO: Inference done 260/346. Dataloading: 0.0017 s / iter. Inference: 1.3486 s / iter. Eval: 0.0003 s / iter. Total: 1.3508 s / iter. ETA=0:01:56
[12/23 19:08:59] d2.evaluation.evaluator INFO: Inference done 264/346. Dataloading: 0.0017 s / iter. Inference: 1.3504 s / iter. Eval: 0.0003 s / iter. Total: 1.3525 s / iter. ETA=0:01:50
[12/23 19:09:05] d2.evaluation.evaluator INFO: Inference done 268/346. Dataloading: 0.0017 s / iter. Inference: 1.3499 s / iter. Eval: 0.0003 s / iter. Total: 1.3521 s / iter. ETA=0:01:45
[12/23 19:09:11] d2.evaluation.evaluator INFO: Inference done 273/346. Dataloading: 0.0017 s / iter. Inference: 1.3483 s / iter. Eval: 0.0003 s / iter. Total: 1.3505 s / iter. ETA=0:01:38
[12/23 19:09:16] d2.evaluation.evaluator INFO: Inference done 278/346. Dataloading: 0.0017 s / iter. Inference: 1.3424 s / iter. Eval: 0.0003 s / iter. Total: 1.3446 s / iter. ETA=0:01:31
[12/23 19:09:22] d2.evaluation.evaluator INFO: Inference done 283/346. Dataloading: 0.0017 s / iter. Inference: 1.3380 s / iter. Eval: 0.0003 s / iter. Total: 1.3402 s / iter. ETA=0:01:24
[12/23 19:09:27] d2.evaluation.evaluator INFO: Inference done 290/346. Dataloading: 0.0017 s / iter. Inference: 1.3250 s / iter. Eval: 0.0003 s / iter. Total: 1.3271 s / iter. ETA=0:01:14
[12/23 19:09:32] d2.evaluation.evaluator INFO: Inference done 293/346. Dataloading: 0.0017 s / iter. Inference: 1.3285 s / iter. Eval: 0.0003 s / iter. Total: 1.3307 s / iter. ETA=0:01:10
[12/23 19:09:40] d2.evaluation.evaluator INFO: Inference done 297/346. Dataloading: 0.0017 s / iter. Inference: 1.3359 s / iter. Eval: 0.0003 s / iter. Total: 1.3381 s / iter. ETA=0:01:05
[12/23 19:09:46] d2.evaluation.evaluator INFO: Inference done 301/346. Dataloading: 0.0017 s / iter. Inference: 1.3374 s / iter. Eval: 0.0003 s / iter. Total: 1.3396 s / iter. ETA=0:01:00
[12/23 19:09:51] d2.evaluation.evaluator INFO: Inference done 305/346. Dataloading: 0.0017 s / iter. Inference: 1.3367 s / iter. Eval: 0.0003 s / iter. Total: 1.3389 s / iter. ETA=0:00:54
[12/23 19:09:56] d2.evaluation.evaluator INFO: Inference done 310/346. Dataloading: 0.0017 s / iter. Inference: 1.3335 s / iter. Eval: 0.0003 s / iter. Total: 1.3357 s / iter. ETA=0:00:48
[12/23 19:10:02] d2.evaluation.evaluator INFO: Inference done 313/346. Dataloading: 0.0017 s / iter. Inference: 1.3385 s / iter. Eval: 0.0003 s / iter. Total: 1.3406 s / iter. ETA=0:00:44
[12/23 19:10:07] d2.evaluation.evaluator INFO: Inference done 316/346. Dataloading: 0.0017 s / iter. Inference: 1.3419 s / iter. Eval: 0.0003 s / iter. Total: 1.3441 s / iter. ETA=0:00:40
[12/23 19:10:13] d2.evaluation.evaluator INFO: Inference done 321/346. Dataloading: 0.0017 s / iter. Inference: 1.3403 s / iter. Eval: 0.0003 s / iter. Total: 1.3425 s / iter. ETA=0:00:33
[12/23 19:10:18] d2.evaluation.evaluator INFO: Inference done 325/346. Dataloading: 0.0017 s / iter. Inference: 1.3397 s / iter. Eval: 0.0003 s / iter. Total: 1.3419 s / iter. ETA=0:00:28
[12/23 19:10:24] d2.evaluation.evaluator INFO: Inference done 329/346. Dataloading: 0.0017 s / iter. Inference: 1.3398 s / iter. Eval: 0.0003 s / iter. Total: 1.3419 s / iter. ETA=0:00:22
[12/23 19:10:30] d2.evaluation.evaluator INFO: Inference done 333/346. Dataloading: 0.0017 s / iter. Inference: 1.3415 s / iter. Eval: 0.0003 s / iter. Total: 1.3437 s / iter. ETA=0:00:17
[12/23 19:10:37] d2.evaluation.evaluator INFO: Inference done 337/346. Dataloading: 0.0017 s / iter. Inference: 1.3473 s / iter. Eval: 0.0003 s / iter. Total: 1.3495 s / iter. ETA=0:00:12
[12/23 19:10:44] d2.evaluation.evaluator INFO: Inference done 342/346. Dataloading: 0.0017 s / iter. Inference: 1.3477 s / iter. Eval: 0.0003 s / iter. Total: 1.3498 s / iter. ETA=0:00:05
[12/23 19:10:49] d2.evaluation.evaluator INFO: Inference done 346/346. Dataloading: 0.0017 s / iter. Inference: 1.3482 s / iter. Eval: 0.0003 s / iter. Total: 1.3504 s / iter. ETA=0:00:00
[12/23 19:11:10] d2.evaluation.evaluator INFO: Total inference time: 0:08:00.501707 (1.409096 s / iter per device, on 4 devices)
[12/23 19:11:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:39 (1.348195 s / iter per device, on 4 devices)
[12/23 19:11:34] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/23 19:11:34] d2.evaluation.coco_evaluation INFO: Saving results to output/vitb/artaxor_5shot/inference/coco_instances_results.json
[12/23 19:11:34] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[12/23 19:11:34] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[12/23 19:11:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.98 seconds.
[12/23 19:11:35] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[12/23 19:11:36] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[12/23 19:11:36] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 42.932 | 64.343 | 46.325 | 0.000 | 0.913 | 43.539 |
[12/23 19:11:36] d2.evaluation.coco_evaluation INFO: target AP50: -1
[12/23 19:11:36] d2.evaluation.coco_evaluation INFO: base AP50: 0.6434346596331042
[12/23 19:11:36] d2.evaluation.coco_evaluation INFO: all AP50: 0.6434346596331042
[12/23 19:11:36] d2.evaluation.coco_evaluation INFO: target AP75: -1
[12/23 19:11:36] d2.evaluation.coco_evaluation INFO: base AP75: 0.4632532889626969
[12/23 19:11:36] d2.evaluation.coco_evaluation INFO: all AP75: 0.4632532889626969
[12/23 19:11:36] d2.evaluation.coco_evaluation INFO: target mAP: -1.0
[12/23 19:11:36] d2.evaluation.coco_evaluation INFO: base mAP: 0.42931986977481856
[12/23 19:11:36] d2.evaluation.coco_evaluation INFO: all mAP: 0.42931986977481856
[12/23 19:11:36] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category    | AP     | category    | AP     |
|:-----------|:-------|:------------|:-------|:------------|:-------|
| Araneae    | 61.392 | Coleoptera  | 37.159 | Diptera     | 25.485 |
| Hemiptera  | 48.432 | Hymenoptera | 17.354 | Lepidoptera | 51.575 |
| Odonata    | 59.126 |             |        |             |        |
[12/23 19:11:36] d2.engine.defaults INFO: Evaluation results for ArTaxOr_test in csv format:
[12/23 19:11:36] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/23 19:11:36] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/23 19:11:36] d2.evaluation.testing INFO: copypaste: 42.9320,64.3435,46.3253,0.0000,0.9130,43.5392
[12/23 19:11:36] d2.evaluation.testing INFO: ###################### ('AP', 42.931986977481856) ######################
