xFormers not available
Command Line Args: Namespace(config_file='configs/neu-det/vitb_shot5_neu-det_finetune.yaml', resume=False, eval_only=True, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/neu-det_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/neu-det_5shot/', 'SOLVER.IMS_PER_BATCH', '4'])
xFormers not available
xFormers not available
xFormers not available
xFormers not available
[12/23 19:39:25 detectron2]: Rank of current process: 0. World size: 4
[12/23 19:39:26 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/23 19:39:26 detectron2]: Command line arguments: Namespace(config_file='configs/neu-det/vitb_shot5_neu-det_finetune.yaml', resume=False, eval_only=True, num_gpus=4, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/neu-det_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/neu-det_5shot/', 'SOLVER.IMS_PER_BATCH', '4'])
[12/23 19:39:26 detectron2]: Contents of args.config_file=configs/neu-det/vitb_shot5_neu-det_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/NEUDET_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("NEUDET_5shot",)
  TEST: ("NEUDET_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 19:39:26 detectron2]: Full config saved to output/vitb/neu-det_5shot/config.yaml
('NEUDET_test',)
[12/23 19:39:32 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vitb/neu-det_5shot/model_final.pth ...
[12/23 19:39:33 d2.data.datasets.coco]: Loaded 360 images in COCO format from datasets/NEUDET/annotations/test.json
[12/23 19:39:33 d2.data.build]: Distribution of instances among all 6 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|    crazing    | 103          |   inclusion   | 159          |  patches   | 222          |
| pitted_surf.. | 106          | rolled-in_s.. | 141          | scratches  | 103          |
|               |              |               |              |            |              |
|     total     | 834          |               |              |            |              |
[12/23 19:39:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/23 19:39:33 d2.data.common]: Serializing 360 elements to byte tensors and concatenating them all ...
[12/23 19:39:33 d2.data.common]: Serialized dataset takes 0.12 MiB
[12/23 19:39:33 d2.evaluation.evaluator]: Start inference on 90 batches
('NEUDET_test',)
('NEUDET_test',)
('NEUDET_test',)
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
xFormers not available
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/23 19:40:04 d2.evaluation.evaluator]: Inference done 11/90. Dataloading: 0.0010 s / iter. Inference: 0.8297 s / iter. Eval: 0.0004 s / iter. Total: 0.8311 s / iter. ETA=0:01:05
[12/23 19:40:09 d2.evaluation.evaluator]: Inference done 16/90. Dataloading: 0.0013 s / iter. Inference: 0.9090 s / iter. Eval: 0.0004 s / iter. Total: 0.9108 s / iter. ETA=0:01:07
[12/23 19:40:14 d2.evaluation.evaluator]: Inference done 20/90. Dataloading: 0.0014 s / iter. Inference: 1.0003 s / iter. Eval: 0.0004 s / iter. Total: 1.0021 s / iter. ETA=0:01:10
[12/23 19:40:19 d2.evaluation.evaluator]: Inference done 27/90. Dataloading: 0.0015 s / iter. Inference: 0.9146 s / iter. Eval: 0.0004 s / iter. Total: 0.9166 s / iter. ETA=0:00:57
[12/23 19:40:25 d2.evaluation.evaluator]: Inference done 34/90. Dataloading: 0.0016 s / iter. Inference: 0.8992 s / iter. Eval: 0.0003 s / iter. Total: 0.9012 s / iter. ETA=0:00:50
[12/23 19:40:30 d2.evaluation.evaluator]: Inference done 40/90. Dataloading: 0.0016 s / iter. Inference: 0.8942 s / iter. Eval: 0.0003 s / iter. Total: 0.8962 s / iter. ETA=0:00:44
[12/23 19:40:36 d2.evaluation.evaluator]: Inference done 47/90. Dataloading: 0.0015 s / iter. Inference: 0.8813 s / iter. Eval: 0.0003 s / iter. Total: 0.8833 s / iter. ETA=0:00:37
[12/23 19:40:41 d2.evaluation.evaluator]: Inference done 54/90. Dataloading: 0.0015 s / iter. Inference: 0.8682 s / iter. Eval: 0.0003 s / iter. Total: 0.8702 s / iter. ETA=0:00:31
[12/23 19:40:47 d2.evaluation.evaluator]: Inference done 61/90. Dataloading: 0.0015 s / iter. Inference: 0.8615 s / iter. Eval: 0.0003 s / iter. Total: 0.8634 s / iter. ETA=0:00:25
[12/23 19:40:52 d2.evaluation.evaluator]: Inference done 67/90. Dataloading: 0.0015 s / iter. Inference: 0.8605 s / iter. Eval: 0.0003 s / iter. Total: 0.8625 s / iter. ETA=0:00:19
[12/23 19:40:57 d2.evaluation.evaluator]: Inference done 73/90. Dataloading: 0.0015 s / iter. Inference: 0.8585 s / iter. Eval: 0.0003 s / iter. Total: 0.8605 s / iter. ETA=0:00:14
[12/23 19:41:02 d2.evaluation.evaluator]: Inference done 79/90. Dataloading: 0.0015 s / iter. Inference: 0.8580 s / iter. Eval: 0.0003 s / iter. Total: 0.8600 s / iter. ETA=0:00:09
[12/23 19:41:08 d2.evaluation.evaluator]: Inference done 85/90. Dataloading: 0.0015 s / iter. Inference: 0.8631 s / iter. Eval: 0.0003 s / iter. Total: 0.8651 s / iter. ETA=0:00:04
[12/23 19:41:31 d2.evaluation.evaluator]: Total inference time: 0:01:32.065972 (1.083129 s / iter per device, on 4 devices)
[12/23 19:41:31 d2.evaluation.evaluator]: Total inference pure compute time: 0:01:11 (0.845589 s / iter per device, on 4 devices)
[12/23 19:41:36 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/23 19:41:36 d2.evaluation.coco_evaluation]: Saving results to output/vitb/neu-det_5shot/inference/coco_instances_results.json
[12/23 19:41:36 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.16s)
creating index...
index created!
[12/23 19:41:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/23 19:41:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.
[12/23 19:41:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/23 19:41:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.05 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.288
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.061
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.088
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.176
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.128
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.255
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.282
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396
[12/23 19:41:36 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 10.919 | 28.800 | 6.103  | 0.517 | 8.848 | 17.635 |
[12/23 19:41:36 d2.evaluation.coco_evaluation]: target AP50: -1
[12/23 19:41:36 d2.evaluation.coco_evaluation]: base AP50: 0.2880023119450457
[12/23 19:41:36 d2.evaluation.coco_evaluation]: all AP50: 0.2880023119450457
[12/23 19:41:36 d2.evaluation.coco_evaluation]: target AP75: -1
[12/23 19:41:36 d2.evaluation.coco_evaluation]: base AP75: 0.06103297133708119
[12/23 19:41:36 d2.evaluation.coco_evaluation]: all AP75: 0.06103297133708119
[12/23 19:41:36 d2.evaluation.coco_evaluation]: target mAP: -1.0
[12/23 19:41:36 d2.evaluation.coco_evaluation]: base mAP: 0.1091854337989073
[12/23 19:41:36 d2.evaluation.coco_evaluation]: all mAP: 0.1091854337989073
[12/23 19:41:36 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category       | AP     | category        | AP    | category   | AP     |
|:---------------|:-------|:----------------|:------|:-----------|:-------|
| crazing        | 1.963  | inclusion       | 8.393 | patches    | 18.852 |
| pitted_surface | 20.924 | rolled-in_scale | 7.186 | scratches  | 8.192  |
[12/23 19:41:36 d2.engine.defaults]: Evaluation results for NEUDET_test in csv format:
[12/23 19:41:36 d2.evaluation.testing]: copypaste: Task: bbox
[12/23 19:41:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/23 19:41:36 d2.evaluation.testing]: copypaste: 10.9185,28.8002,6.1033,0.5167,8.8475,17.6349
[12/23 19:41:36 d2.evaluation.testing]: ###################### ('AP', 10.918543379890732) ######################
