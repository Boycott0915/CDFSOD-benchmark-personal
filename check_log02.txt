(base) fee@ubuntu-R8428-A12:~/sdb_flf/project_zyh/CDFSOD-benchmark$ conda activate cdfsod
(cdfsod) fee@ubuntu-R8428-A12:~/sdb_flf/project_zyh/CDFSOD-benchmark$ bash main_results.sh
>>> 正在补全评价: artaxor 1shot...
xFormers not available
Command Line Args: Namespace(config_file='configs/artaxor/vitb_shot1_artaxor_finetune.yaml', resume=False, eval_only=True,
 num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/artaxo
r_1shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/
vitb/artaxor_1shot/'])
[12/23 16:29:21 detectron2]: Rank of current process: 0. World size: 1
[12/23 16:29:22 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute
_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoo
lset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenm
p -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -
DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing
-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter
-Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-
stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=
always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=form
at -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512
=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MK
LDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,

[12/23 16:29:22 detectron2]: Command line arguments: Namespace(config_file='configs/artaxor/vitb_shot1_artaxor_finetune.ya
ml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['M
ODEL.WEIGHTS', 'output/vitb/artaxor_1shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd
_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/artaxor_1shot/'])
[12/23 16:29:22 detectron2]: Contents of args.config_file=configs/artaxor/vitb_shot1_artaxor_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/ArTaxOr_1shot.vitb14.bbox.p1.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("ArTaxOr_1shot",)
  TEST: ("ArTaxOr_test",)
TEST:
  EVAL_PERIOD: 40
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (20, 35)
  MAX_ITER: 40
  WARMUP_ITERS: 10
  CHECKPOINT_PERIOD: 40
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 16:29:22 detectron2]: Full config saved to output/vitb/artaxor_1shot/config.yaml
('ArTaxOr_test',)
[12/23 16:29:27 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vitb/artaxor_1shot/model_final.pth ...
[12/23 16:29:28 d2.data.datasets.coco]: Loaded 1383 images in COCO format from datasets/ArTaxOr/annotations/test.json
[12/23 16:29:28 d2.data.build]: Distribution of instances among all 7 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 455          | Coleoptera  | 145          |   Diptera   | 35           |
| Hemiptera  | 474          | Hymenoptera | 60           | Lepidoptera | 136          |
|  Odonata   | 323          |             |              |             |              |
|   total    | 1628         |             |              |             |              |
[12/23 16:29:28 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_l
ength=(800, 800), max_size=1333, sample_style='choice')]
[12/23 16:29:28 d2.data.common]: Serializing 1383 elements to byte tensors and concatenating them all ...
[12/23 16:29:28 d2.data.common]: Serialized dataset takes 0.40 MiB
[12/23 16:29:28 d2.evaluation.evaluator]: Start inference on 1383 batches
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid:
 in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/nati
ve/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/23 16:29:37 d2.evaluation.evaluator]: Inference done 11/1383. Dataloading: 0.0013 s / iter. Inference: 0.7361 s / iter
. Eval: 0.0003 s / iter. Total: 0.7377 s / iter. ETA=0:16:52
[12/23 16:29:42 d2.evaluation.evaluator]: Inference done 21/1383. Dataloading: 0.0017 s / iter. Inference: 0.6062 s / iter
. Eval: 0.0003 s / iter. Total: 0.6083 s / iter. ETA=0:13:48
[12/23 16:29:48 d2.evaluation.evaluator]: Inference done 31/1383. Dataloading: 0.0018 s / iter. Inference: 0.5889 s / iter
. Eval: 0.0003 s / iter. Total: 0.5911 s / iter. ETA=0:13:19
Traceback (most recent call last):
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 208, in <module>
    launch(
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/launch.py", line 82, in launch
    main_func(*args)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 184, in main
    res = Trainer.test(cfg, model)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/defaults.py", line 622, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/evaluation/evaluator.py", line 181, in infer
ence_on_dataset
    outputs = model(inputs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/modeling/meta_arch/devit.py", line 1450, in
forward
    embedding = rp(embedding)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in
forward
    input = module(input)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in
forward
    return F.batch_norm(
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_
norm
    return torch.batch_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 23.52 GiB total capacity; 8.87 GiB alr
eady allocated; 1.23 GiB free; 12.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setti
ng max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
>>> 正在补全评价: artaxor 5shot...
xFormers not available
Command Line Args: Namespace(config_file='configs/artaxor/vitb_shot5_artaxor_finetune.yaml', resume=False, eval_only=True,
 num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/artaxo
r_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/
vitb/artaxor_5shot/'])
[12/23 16:29:59 detectron2]: Rank of current process: 0. World size: 1
[12/23 16:30:00 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute
_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoo
lset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenm
p -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -
DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing
-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter
-Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-
stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=
always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=form
at -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512
=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MK
LDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,

[12/23 16:30:00 detectron2]: Command line arguments: Namespace(config_file='configs/artaxor/vitb_shot5_artaxor_finetune.ya
ml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['M
ODEL.WEIGHTS', 'output/vitb/artaxor_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd
_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/artaxor_5shot/'])
[12/23 16:30:00 detectron2]: Contents of args.config_file=configs/artaxor/vitb_shot5_artaxor_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/ArTaxOr_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("ArTaxOr_5shot",)
  TEST: ("ArTaxOr_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 16:30:00 detectron2]: Full config saved to output/vitb/artaxor_5shot/config.yaml
('ArTaxOr_test',)
[12/23 16:30:05 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vitb/artaxor_5shot/model_final.pth ...
[12/23 16:30:06 d2.data.datasets.coco]: Loaded 1383 images in COCO format from datasets/ArTaxOr/annotations/test.json
[12/23 16:30:06 d2.data.build]: Distribution of instances among all 7 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 455          | Coleoptera  | 145          |   Diptera   | 35           |
| Hemiptera  | 474          | Hymenoptera | 60           | Lepidoptera | 136          |
|  Odonata   | 323          |             |              |             |              |
|   total    | 1628         |             |              |             |              |
[12/23 16:30:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_l
ength=(800, 800), max_size=1333, sample_style='choice')]
[12/23 16:30:06 d2.data.common]: Serializing 1383 elements to byte tensors and concatenating them all ...
[12/23 16:30:06 d2.data.common]: Serialized dataset takes 0.40 MiB
[12/23 16:30:06 d2.evaluation.evaluator]: Start inference on 1383 batches
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid:
 in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/nati
ve/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/23 16:30:15 d2.evaluation.evaluator]: Inference done 11/1383. Dataloading: 0.0016 s / iter. Inference: 0.7345 s / iter
. Eval: 0.0003 s / iter. Total: 0.7364 s / iter. ETA=0:16:50
[12/23 16:30:21 d2.evaluation.evaluator]: Inference done 21/1383. Dataloading: 0.0020 s / iter. Inference: 0.6077 s / iter
. Eval: 0.0003 s / iter. Total: 0.6101 s / iter. ETA=0:13:50
[12/23 16:30:26 d2.evaluation.evaluator]: Inference done 31/1383. Dataloading: 0.0020 s / iter. Inference: 0.5902 s / iter
. Eval: 0.0003 s / iter. Total: 0.5926 s / iter. ETA=0:13:21
Traceback (most recent call last):
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 208, in <module>
    launch(
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/launch.py", line 82, in launch
    main_func(*args)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 184, in main
    res = Trainer.test(cfg, model)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/defaults.py", line 622, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/evaluation/evaluator.py", line 181, in infer
ence_on_dataset
    outputs = model(inputs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/modeling/meta_arch/devit.py", line 1450, in
forward
    embedding = rp(embedding)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in
forward
    input = module(input)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in
forward
    return F.batch_norm(
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_
norm
    return torch.batch_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 23.52 GiB total capacity; 8.87 GiB alr
eady allocated; 1.23 GiB free; 12.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setti
ng max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
>>> 正在补全评价: artaxor 10shot...
xFormers not available
Command Line Args: Namespace(config_file='configs/artaxor/vitb_shot10_artaxor_finetune.yaml', resume=False, eval_only=True
, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/artax
or_10shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'outpu
t/vitb/artaxor_10shot/'])
[12/23 16:30:38 detectron2]: Rank of current process: 0. World size: 1
[12/23 16:30:39 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute
_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoo
lset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenm
p -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -
DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing
-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter
-Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-
stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=
always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=form
at -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512
=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MK
LDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,

[12/23 16:30:39 detectron2]: Command line arguments: Namespace(config_file='configs/artaxor/vitb_shot10_artaxor_finetune.y
aml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['
MODEL.WEIGHTS', 'output/vitb/artaxor_10shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_o
vd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/artaxor_10shot/'])
[12/23 16:30:39 detectron2]: Contents of args.config_file=configs/artaxor/vitb_shot10_artaxor_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/ArTaxOr_10shot.vitb14.bbox.p10.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("ArTaxOr_10shot",)
  TEST: ("ArTaxOr_test",)
TEST:
  EVAL_PERIOD: 200
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (120, 180)
  MAX_ITER: 200
  WARMUP_ITERS: 50
  CHECKPOINT_PERIOD: 200
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 16:30:39 detectron2]: Full config saved to output/vitb/artaxor_10shot/config.yaml
('ArTaxOr_test',)
[12/23 16:30:44 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vitb/artaxor_10shot/model_final.pth ...
[12/23 16:30:45 d2.data.datasets.coco]: Loaded 1383 images in COCO format from datasets/ArTaxOr/annotations/test.json
[12/23 16:30:45 d2.data.build]: Distribution of instances among all 7 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|  Araneae   | 455          | Coleoptera  | 145          |   Diptera   | 35           |
| Hemiptera  | 474          | Hymenoptera | 60           | Lepidoptera | 136          |
|  Odonata   | 323          |             |              |             |              |
|   total    | 1628         |             |              |             |              |
[12/23 16:30:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_l
ength=(800, 800), max_size=1333, sample_style='choice')]
[12/23 16:30:45 d2.data.common]: Serializing 1383 elements to byte tensors and concatenating them all ...
[12/23 16:30:45 d2.data.common]: Serialized dataset takes 0.40 MiB
[12/23 16:30:45 d2.evaluation.evaluator]: Start inference on 1383 batches
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid:
 in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/nati
ve/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/23 16:30:54 d2.evaluation.evaluator]: Inference done 11/1383. Dataloading: 0.0014 s / iter. Inference: 0.7162 s / iter
. Eval: 0.0002 s / iter. Total: 0.7178 s / iter. ETA=0:16:24
[12/23 16:30:59 d2.evaluation.evaluator]: Inference done 20/1383. Dataloading: 0.0021 s / iter. Inference: 0.6233 s / iter
. Eval: 0.0003 s / iter. Total: 0.6257 s / iter. ETA=0:14:12
[12/23 16:31:04 d2.evaluation.evaluator]: Inference done 30/1383. Dataloading: 0.0020 s / iter. Inference: 0.5771 s / iter
. Eval: 0.0003 s / iter. Total: 0.5795 s / iter. ETA=0:13:04
[12/23 16:31:10 d2.evaluation.evaluator]: Inference done 39/1383. Dataloading: 0.0020 s / iter. Inference: 0.5855 s / iter
. Eval: 0.0003 s / iter. Total: 0.5879 s / iter. ETA=0:13:10
Traceback (most recent call last):
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 208, in <module>
    launch(
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/launch.py", line 82, in launch
    main_func(*args)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 184, in main
    res = Trainer.test(cfg, model)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/defaults.py", line 622, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/evaluation/evaluator.py", line 181, in infer
ence_on_dataset
    outputs = model(inputs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/modeling/meta_arch/devit.py", line 1450, in
forward
    embedding = rp(embedding)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in
forward
    input = module(input)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in
forward
    return F.batch_norm(
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_
norm
    return torch.batch_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 23.52 GiB total capacity; 8.87 GiB alr
eady allocated; 1.23 GiB free; 12.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setti
ng max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
>>> 正在补全评价: clipart1k 1shot...
xFormers not available
Command Line Args: Namespace(config_file='configs/clipart1k/vitb_shot1_clipart1k_finetune.yaml', resume=False, eval_only=T
rue, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/cl
ipart1k_1shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'o
utput/vitb/clipart1k_1shot/'])
[12/23 16:31:17 detectron2]: Rank of current process: 0. World size: 1
[12/23 16:31:18 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute
_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoo
lset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenm
p -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -
DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing
-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter
-Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-
stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=
always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=form
at -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512
=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MK
LDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,

[12/23 16:31:18 detectron2]: Command line arguments: Namespace(config_file='configs/clipart1k/vitb_shot1_clipart1k_finetun
e.yaml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts
=['MODEL.WEIGHTS', 'output/vitb/clipart1k_1shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_
1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/clipart1k_1shot/'])
[12/23 16:31:18 detectron2]: Contents of args.config_file=configs/clipart1k/vitb_shot1_clipart1k_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/clipart1k_1shot.vitb14.bbox.p1.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("clipart1k_1shot",)
  TEST: ("clipart1k_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (20, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 16:31:18 detectron2]: Full config saved to output/vitb/clipart1k_1shot/config.yaml
('clipart1k_test',)
[12/23 16:31:23 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vitb/clipart1k_1shot/model_final.pth ...
[12/23 16:31:24 d2.data.datasets.coco]: Loaded 500 images in COCO format from datasets/clipart1k/annotations/test.json
[12/23 16:31:24 d2.data.build]: Distribution of instances among all 20 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|   sheep    | 33           |    chair    | 163          |    boat     | 74           |
|   bottle   | 74           | diningtable | 50           |    sofa     | 21           |
|    cow     | 21           |  motorbike  | 10           |     car     | 84           |
| aeroplane  | 41           |     cat     | 23           |    train    | 26           |
|   person   | 566          |   bicycle   | 16           | pottedplant | 94           |
|    bird    | 124          |     dog     | 24           |     bus     | 8            |
| tvmonitor  | 40           |    horse    | 34           |             |              |
|   total    | 1526         |             |              |             |              |
[12/23 16:31:24 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_l
ength=(800, 800), max_size=1333, sample_style='choice')]
[12/23 16:31:24 d2.data.common]: Serializing 500 elements to byte tensors and concatenating them all ...
[12/23 16:31:24 d2.data.common]: Serialized dataset takes 0.18 MiB
[12/23 16:31:24 d2.evaluation.evaluator]: Start inference on 500 batches
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid:
 in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/nati
ve/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Traceback (most recent call last):
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 208, in <module>
    launch(
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/launch.py", line 82, in launch
    main_func(*args)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 184, in main
    res = Trainer.test(cfg, model)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/defaults.py", line 622, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/evaluation/evaluator.py", line 181, in infer
ence_on_dataset
    outputs = model(inputs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/modeling/meta_arch/devit.py", line 1450, in
forward
    embedding = rp(embedding)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in
forward
    input = module(input)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in
forward
    return F.batch_norm(
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_
norm
    return torch.batch_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.62 GiB (GPU 0; 23.52 GiB total capacity; 9.57 GiB alr
eady allocated; 744.94 MiB free; 12.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try set
ting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
>>> 正在补全评价: clipart1k 5shot...
xFormers not available
Command Line Args: Namespace(config_file='configs/clipart1k/vitb_shot5_clipart1k_finetune.yaml', resume=False, eval_only=T
rue, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/cl
ipart1k_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'o
utput/vitb/clipart1k_5shot/'])
[12/23 16:31:33 detectron2]: Rank of current process: 0. World size: 1
[12/23 16:31:34 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute
_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoo
lset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenm
p -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -
DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing
-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter
-Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-
stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=
always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=form
at -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512
=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MK
LDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,

[12/23 16:31:34 detectron2]: Command line arguments: Namespace(config_file='configs/clipart1k/vitb_shot5_clipart1k_finetun
e.yaml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts
=['MODEL.WEIGHTS', 'output/vitb/clipart1k_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_
1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/clipart1k_5shot/'])
[12/23 16:31:34 detectron2]: Contents of args.config_file=configs/clipart1k/vitb_shot5_clipart1k_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/clipart1k_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("clipart1k_5shot",)
  TEST: ("clipart1k_test",)
TEST:
  EVAL_PERIOD: 250
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (100, 180)
  MAX_ITER: 250
  WARMUP_ITERS: 50
  CHECKPOINT_PERIOD: 250
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 16:31:34 detectron2]: Full config saved to output/vitb/clipart1k_5shot/config.yaml
('clipart1k_test',)
[12/23 16:31:39 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vitb/clipart1k_5shot/model_final.pth ...
[12/23 16:31:40 d2.data.datasets.coco]: Loaded 500 images in COCO format from datasets/clipart1k/annotations/test.json
[12/23 16:31:40 d2.data.build]: Distribution of instances among all 20 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|   sheep    | 33           |    chair    | 163          |    boat     | 74           |
|   bottle   | 74           | diningtable | 50           |    sofa     | 21           |
|    cow     | 21           |  motorbike  | 10           |     car     | 84           |
| aeroplane  | 41           |     cat     | 23           |    train    | 26           |
|   person   | 566          |   bicycle   | 16           | pottedplant | 94           |
|    bird    | 124          |     dog     | 24           |     bus     | 8            |
| tvmonitor  | 40           |    horse    | 34           |             |              |
|   total    | 1526         |             |              |             |              |
[12/23 16:31:40 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_l
ength=(800, 800), max_size=1333, sample_style='choice')]
[12/23 16:31:40 d2.data.common]: Serializing 500 elements to byte tensors and concatenating them all ...
[12/23 16:31:40 d2.data.common]: Serialized dataset takes 0.18 MiB
[12/23 16:31:40 d2.evaluation.evaluator]: Start inference on 500 batches
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid:
 in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/nati
ve/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Traceback (most recent call last):
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 208, in <module>
    launch(
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/launch.py", line 82, in launch
    main_func(*args)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 184, in main
    res = Trainer.test(cfg, model)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/defaults.py", line 622, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/evaluation/evaluator.py", line 181, in infer
ence_on_dataset
    outputs = model(inputs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/modeling/meta_arch/devit.py", line 1450, in
forward
    embedding = rp(embedding)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in
forward
    input = module(input)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in
forward
    return F.batch_norm(
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_
norm
    return torch.batch_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.62 GiB (GPU 0; 23.52 GiB total capacity; 9.57 GiB alr
eady allocated; 744.94 MiB free; 12.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try set
ting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
>>> 正在补全评价: clipart1k 10shot...
xFormers not available
Command Line Args: Namespace(config_file='configs/clipart1k/vitb_shot10_clipart1k_finetune.yaml', resume=False, eval_only=
True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/c
lipart1k_10shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR',
'output/vitb/clipart1k_10shot/'])
[12/23 16:31:49 detectron2]: Rank of current process: 0. World size: 1
[12/23 16:31:50 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute
_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoo
lset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenm
p -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -
DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing
-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter
-Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-
stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=
always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=form
at -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512
=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MK
LDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,

[12/23 16:31:50 detectron2]: Command line arguments: Namespace(config_file='configs/clipart1k/vitb_shot10_clipart1k_finetu
ne.yaml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opt
s=['MODEL.WEIGHTS', 'output/vitb/clipart1k_10shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C
4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/clipart1k_10shot/'])
[12/23 16:31:50 detectron2]: Contents of args.config_file=configs/clipart1k/vitb_shot10_clipart1k_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/clipart1k_10shot.vitb14.bbox.p10.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("clipart1k_10shot",)
  TEST: ("clipart1k_test",)
TEST:
  EVAL_PERIOD: 500
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (250, 400)
  MAX_ITER: 500
  WARMUP_ITERS: 100
  CHECKPOINT_PERIOD: 500
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 16:31:50 detectron2]: Full config saved to output/vitb/clipart1k_10shot/config.yaml
('clipart1k_test',)
[12/23 16:31:55 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vitb/clipart1k_10shot/model_final.pth ...
[12/23 16:31:56 d2.data.datasets.coco]: Loaded 500 images in COCO format from datasets/clipart1k/annotations/test.json
[12/23 16:31:56 d2.data.build]: Distribution of instances among all 20 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
|   sheep    | 33           |    chair    | 163          |    boat     | 74           |
|   bottle   | 74           | diningtable | 50           |    sofa     | 21           |
|    cow     | 21           |  motorbike  | 10           |     car     | 84           |
| aeroplane  | 41           |     cat     | 23           |    train    | 26           |
|   person   | 566          |   bicycle   | 16           | pottedplant | 94           |
|    bird    | 124          |     dog     | 24           |     bus     | 8            |
| tvmonitor  | 40           |    horse    | 34           |             |              |
|   total    | 1526         |             |              |             |              |
[12/23 16:31:56 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_l
ength=(800, 800), max_size=1333, sample_style='choice')]
[12/23 16:31:56 d2.data.common]: Serializing 500 elements to byte tensors and concatenating them all ...
[12/23 16:31:56 d2.data.common]: Serialized dataset takes 0.18 MiB
[12/23 16:31:56 d2.evaluation.evaluator]: Start inference on 500 batches
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid:
 in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/nati
ve/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Traceback (most recent call last):
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 208, in <module>
    launch(
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/launch.py", line 82, in launch
    main_func(*args)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 184, in main
    res = Trainer.test(cfg, model)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/defaults.py", line 622, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/evaluation/evaluator.py", line 181, in infer
ence_on_dataset
    outputs = model(inputs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/modeling/meta_arch/devit.py", line 1450, in
forward
    embedding = rp(embedding)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in
forward
    input = module(input)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in
forward
    return F.batch_norm(
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_
norm
    return torch.batch_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.62 GiB (GPU 0; 23.52 GiB total capacity; 9.57 GiB alr
eady allocated; 742.94 MiB free; 12.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try set
ting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
>>> [警告] 找不到权重文件: output/vitb/dior_1shot/model_final.pth
>>> [警告] 找不到权重文件: output/vitb/dior_5shot/model_final.pth
>>> [警告] 找不到权重文件: output/vitb/dior_10shot/model_final.pth
>>> 正在补全评价: neu-det 1shot...
xFormers not available
Command Line Args: Namespace(config_file='configs/neu-det/vitb_shot1_neu-det_finetune.yaml', resume=False, eval_only=True,
 num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/neu-de
t_1shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/
vitb/neu-det_1shot/'])
[12/23 16:32:05 detectron2]: Rank of current process: 0. World size: 1
[12/23 16:32:06 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute
_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoo
lset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenm
p -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -
DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing
-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter
-Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-
stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=
always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=form
at -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512
=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MK
LDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,

[12/23 16:32:06 detectron2]: Command line arguments: Namespace(config_file='configs/neu-det/vitb_shot1_neu-det_finetune.ya
ml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['M
ODEL.WEIGHTS', 'output/vitb/neu-det_1shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd
_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/neu-det_1shot/'])
[12/23 16:32:06 detectron2]: Contents of args.config_file=configs/neu-det/vitb_shot1_neu-det_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/NEUDET_1shot.vitb14.bbox.p1.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("NEUDET_1shot",)
  TEST: ("NEUDET_test",)
TEST:
  EVAL_PERIOD: 40
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (20, 35)
  MAX_ITER: 40
  WARMUP_ITERS: 10
  CHECKPOINT_PERIOD: 40
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 16:32:06 detectron2]: Full config saved to output/vitb/neu-det_1shot/config.yaml
('NEUDET_test',)
[12/23 16:32:11 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vitb/neu-det_1shot/model_final.pth ...
[12/23 16:32:12 d2.data.datasets.coco]: Loaded 360 images in COCO format from datasets/NEUDET/annotations/test.json
[12/23 16:32:12 d2.data.build]: Distribution of instances among all 6 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|    crazing    | 103          |   inclusion   | 159          |  patches   | 222          |
| pitted_surf.. | 106          | rolled-in_s.. | 141          | scratches  | 103          |
|               |              |               |              |            |              |
|     total     | 834          |               |              |            |              |
[12/23 16:32:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_l
ength=(800, 800), max_size=1333, sample_style='choice')]
[12/23 16:32:12 d2.data.common]: Serializing 360 elements to byte tensors and concatenating them all ...
[12/23 16:32:12 d2.data.common]: Serialized dataset takes 0.12 MiB
[12/23 16:32:12 d2.evaluation.evaluator]: Start inference on 360 batches
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid:
 in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/nati
ve/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/23 16:32:18 d2.evaluation.evaluator]: Inference done 11/360. Dataloading: 0.0010 s / iter. Inference: 0.4351 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4365 s / iter. ETA=0:02:32
[12/23 16:32:23 d2.evaluation.evaluator]: Inference done 20/360. Dataloading: 0.0016 s / iter. Inference: 0.5108 s / iter.
 Eval: 0.0003 s / iter. Total: 0.5129 s / iter. ETA=0:02:54
[12/23 16:32:28 d2.evaluation.evaluator]: Inference done 33/360. Dataloading: 0.0017 s / iter. Inference: 0.4620 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4641 s / iter. ETA=0:02:31
^[[A^[[A^[[B^[[B^[[A^[[A^[[B^[[B^[[B[12/23 16:32:33 d2.evaluation.evaluator]: Inference done 44/360. Dataloading: 0.0017 s
 / iter. Inference: 0.4662 s / iter. Eval: 0.0003 s / iter. Total: 0.4684 s / iter. ETA=0:02:28
[12/23 16:32:39 d2.evaluation.evaluator]: Inference done 56/360. Dataloading: 0.0017 s / iter. Inference: 0.4609 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4630 s / iter. ETA=0:02:20
[12/23 16:32:44 d2.evaluation.evaluator]: Inference done 68/360. Dataloading: 0.0046 s / iter. Inference: 0.4560 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4610 s / iter. ETA=0:02:14
[12/23 16:32:49 d2.evaluation.evaluator]: Inference done 80/360. Dataloading: 0.0041 s / iter. Inference: 0.4513 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4559 s / iter. ETA=0:02:07
[12/23 16:32:54 d2.evaluation.evaluator]: Inference done 93/360. Dataloading: 0.0037 s / iter. Inference: 0.4423 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4464 s / iter. ETA=0:01:59
[12/23 16:33:00 d2.evaluation.evaluator]: Inference done 104/360. Dataloading: 0.0035 s / iter. Inference: 0.4473 s / iter
. Eval: 0.0003 s / iter. Total: 0.4512 s / iter. ETA=0:01:55
[12/23 16:33:05 d2.evaluation.evaluator]: Inference done 115/360. Dataloading: 0.0033 s / iter. Inference: 0.4514 s / iter
. Eval: 0.0003 s / iter. Total: 0.4552 s / iter. ETA=0:01:51
[12/23 16:33:10 d2.evaluation.evaluator]: Inference done 128/360. Dataloading: 0.0032 s / iter. Inference: 0.4465 s / iter
. Eval: 0.0003 s / iter. Total: 0.4501 s / iter. ETA=0:01:44
[12/23 16:33:16 d2.evaluation.evaluator]: Inference done 139/360. Dataloading: 0.0030 s / iter. Inference: 0.4478 s / iter
. Eval: 0.0003 s / iter. Total: 0.4513 s / iter. ETA=0:01:39
[12/23 16:33:21 d2.evaluation.evaluator]: Inference done 150/360. Dataloading: 0.0029 s / iter. Inference: 0.4506 s / iter
. Eval: 0.0003 s / iter. Total: 0.4539 s / iter. ETA=0:01:35
Traceback (most recent call last):
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 208, in <module>
    launch(
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/launch.py", line 82, in launch
    main_func(*args)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 184, in main
    res = Trainer.test(cfg, model)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/defaults.py", line 622, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/evaluation/evaluator.py", line 181, in infer
ence_on_dataset
    outputs = model(inputs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/modeling/meta_arch/devit.py", line 1450, in
forward
    embedding = rp(embedding)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in
forward
    input = module(input)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 463, in forwa
rd
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 459, in _conv
_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.84 GiB (GPU 0; 23.52 GiB total capacity; 8.86 GiB alr
eady allocated; 780.94 MiB free; 12.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try set
ting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
>>> 正在补全评价: neu-det 5shot...
xFormers not available
Command Line Args: Namespace(config_file='configs/neu-det/vitb_shot5_neu-det_finetune.yaml', resume=False, eval_only=True,
 num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/neu-de
t_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'output/
vitb/neu-det_5shot/'])
[12/23 16:33:28 detectron2]: Rank of current process: 0. World size: 1
[12/23 16:33:29 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute
_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoo
lset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenm
p -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -
DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing
-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter
-Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-
stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=
always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=form
at -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512
=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MK
LDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,

[12/23 16:33:29 detectron2]: Command line arguments: Namespace(config_file='configs/neu-det/vitb_shot5_neu-det_finetune.ya
ml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['M
ODEL.WEIGHTS', 'output/vitb/neu-det_5shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd
_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/neu-det_5shot/'])
[12/23 16:33:29 detectron2]: Contents of args.config_file=configs/neu-det/vitb_shot5_neu-det_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/NEUDET_5shot.vitb14.bbox.p5.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("NEUDET_5shot",)
  TEST: ("NEUDET_test",)
TEST:
  EVAL_PERIOD: 100
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (50, 80)
  MAX_ITER: 100
  WARMUP_ITERS: 20
  CHECKPOINT_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 16:33:29 detectron2]: Full config saved to output/vitb/neu-det_5shot/config.yaml
('NEUDET_test',)
[12/23 16:33:34 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vitb/neu-det_5shot/model_final.pth ...
[12/23 16:33:35 d2.data.datasets.coco]: Loaded 360 images in COCO format from datasets/NEUDET/annotations/test.json
[12/23 16:33:35 d2.data.build]: Distribution of instances among all 6 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|    crazing    | 103          |   inclusion   | 159          |  patches   | 222          |
| pitted_surf.. | 106          | rolled-in_s.. | 141          | scratches  | 103          |
|               |              |               |              |            |              |
|     total     | 834          |               |              |            |              |
[12/23 16:33:35 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_l
ength=(800, 800), max_size=1333, sample_style='choice')]
[12/23 16:33:35 d2.data.common]: Serializing 360 elements to byte tensors and concatenating them all ...
[12/23 16:33:35 d2.data.common]: Serialized dataset takes 0.12 MiB
[12/23 16:33:35 d2.evaluation.evaluator]: Start inference on 360 batches
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid:
 in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/nati
ve/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/23 16:33:41 d2.evaluation.evaluator]: Inference done 11/360. Dataloading: 0.0010 s / iter. Inference: 0.4362 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4376 s / iter. ETA=0:02:32
[12/23 16:33:46 d2.evaluation.evaluator]: Inference done 21/360. Dataloading: 0.0014 s / iter. Inference: 0.5027 s / iter.
 Eval: 0.0003 s / iter. Total: 0.5045 s / iter. ETA=0:02:51
[12/23 16:33:52 d2.evaluation.evaluator]: Inference done 34/360. Dataloading: 0.0015 s / iter. Inference: 0.4707 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4726 s / iter. ETA=0:02:34
[12/23 16:33:57 d2.evaluation.evaluator]: Inference done 45/360. Dataloading: 0.0015 s / iter. Inference: 0.4677 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4696 s / iter. ETA=0:02:27
[12/23 16:34:02 d2.evaluation.evaluator]: Inference done 57/360. Dataloading: 0.0016 s / iter. Inference: 0.4589 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4608 s / iter. ETA=0:02:19
[12/23 16:34:07 d2.evaluation.evaluator]: Inference done 68/360. Dataloading: 0.0016 s / iter. Inference: 0.4589 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4609 s / iter. ETA=0:02:14
[12/23 16:34:12 d2.evaluation.evaluator]: Inference done 80/360. Dataloading: 0.0016 s / iter. Inference: 0.4539 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4558 s / iter. ETA=0:02:07
[12/23 16:34:17 d2.evaluation.evaluator]: Inference done 93/360. Dataloading: 0.0016 s / iter. Inference: 0.4445 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4464 s / iter. ETA=0:01:59
[12/23 16:34:23 d2.evaluation.evaluator]: Inference done 104/360. Dataloading: 0.0015 s / iter. Inference: 0.4493 s / iter
. Eval: 0.0003 s / iter. Total: 0.4513 s / iter. ETA=0:01:55
[12/23 16:34:28 d2.evaluation.evaluator]: Inference done 115/360. Dataloading: 0.0015 s / iter. Inference: 0.4533 s / iter
. Eval: 0.0003 s / iter. Total: 0.4553 s / iter. ETA=0:01:51
[12/23 16:34:33 d2.evaluation.evaluator]: Inference done 128/360. Dataloading: 0.0015 s / iter. Inference: 0.4481 s / iter
. Eval: 0.0003 s / iter. Total: 0.4500 s / iter. ETA=0:01:44
[12/23 16:34:39 d2.evaluation.evaluator]: Inference done 139/360. Dataloading: 0.0015 s / iter. Inference: 0.4498 s / iter
. Eval: 0.0003 s / iter. Total: 0.4517 s / iter. ETA=0:01:39
[12/23 16:34:44 d2.evaluation.evaluator]: Inference done 150/360. Dataloading: 0.0015 s / iter. Inference: 0.4524 s / iter
. Eval: 0.0003 s / iter. Total: 0.4544 s / iter. ETA=0:01:35
Traceback (most recent call last):
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 208, in <module>
    launch(
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/launch.py", line 82, in launch
    main_func(*args)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 184, in main
    res = Trainer.test(cfg, model)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/defaults.py", line 622, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/evaluation/evaluator.py", line 181, in infer
ence_on_dataset
    outputs = model(inputs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/modeling/meta_arch/devit.py", line 1450, in
forward
    embedding = rp(embedding)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in
forward
    input = module(input)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 463, in forwa
rd
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 459, in _conv
_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.84 GiB (GPU 0; 23.52 GiB total capacity; 8.86 GiB alr
eady allocated; 780.94 MiB free; 12.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try set
ting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
>>> 正在补全评价: neu-det 10shot...
xFormers not available
Command Line Args: Namespace(config_file='configs/neu-det/vitb_shot10_neu-det_finetune.yaml', resume=False, eval_only=True
, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['MODEL.WEIGHTS', 'output/vitb/neu-d
et_10shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml', 'OUTPUT_DIR', 'outpu
t/vitb/neu-det_10shot/'])
[12/23 16:34:51 detectron2]: Rank of current process: 0. World size: 1
[12/23 16:34:52 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) [GCC 13.3.0]
numpy                   1.22.4
detectron2              RegionCLIP @/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 11.8
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   NVIDIA GeForce RTX 4090 (arch=8.9)
CUDA_HOME               /usr/local/cuda-11.8
Pillow                  9.5.0
torchvision             0.14.1+cu117 @/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.8
cv2                     Not found
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute
_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.9.7  (built against CUDA 11.8)
    - Built with CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoo
lset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenm
p -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -
DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing
-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter
-Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-
stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=
always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=form
at -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512
=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MK
LDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,

[12/23 16:34:52 detectron2]: Command line arguments: Namespace(config_file='configs/neu-det/vitb_shot10_neu-det_finetune.y
aml', resume=False, eval_only=True, num_gpus=1, controller=False, num_machines=1, machine_rank=0, dist_url='auto', opts=['
MODEL.WEIGHTS', 'output/vitb/neu-det_10shot/model_final.pth', 'DE.OFFLINE_RPN_CONFIG', 'configs/RPN/mask_rcnn_R_50_C4_1x_o
vd_FSD.yaml', 'OUTPUT_DIR', 'output/vitb/neu-det_10shot/'])
[12/23 16:34:52 detectron2]: Contents of args.config_file=configs/neu-det/vitb_shot10_neu-det_finetune.yaml:
_BASE_: ../Base-RCNN-C4.yaml
DE:
  CLASS_PROTOTYPES: prototypes_init/NEUDET_10shot.vitb14.bbox.p10.sk.pkl
  BG_PROTOTYPES: weights/initial/background/background_prototypes.vitb14.pth
  BG_CLS_LOSS_WEIGHT: 0.2
  TOPK: 5
  SET_CD_VITO: true
  ATTN_FUSE_RATIO: 0.7
MODEL:
  META_ARCHITECTURE: OpenSetDetectorWithExamples
  BACKBONE:
    NAME: build_dino_v2_vit
    TYPE: base    # base, small
  WEIGHTS: ''
  MASK_ON: false
  RPN:
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: [res4]
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.001
  ROI_BOX_HEAD:
    NAME: ''
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    CLS_AGNOSTIC_BBOX_REG: true
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
DATASETS:
  TRAIN: ("NEUDET_10shot",)
  TEST: ("NEUDET_test",)
TEST:
  EVAL_PERIOD: 200
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.002
  STEPS: (120, 180)
  MAX_ITER: 200
  WARMUP_ITERS: 50
  CHECKPOINT_PERIOD: 200
INPUT:
  MIN_SIZE_TRAIN_SAMPLING: choice
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
  FORMAT: RGB


[12/23 16:34:52 detectron2]: Full config saved to output/vitb/neu-det_10shot/config.yaml
('NEUDET_test',)
[12/23 16:34:57 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vitb/neu-det_10shot/model_final.pth ...
[12/23 16:34:58 d2.data.datasets.coco]: Loaded 360 images in COCO format from datasets/NEUDET/annotations/test.json
[12/23 16:34:58 d2.data.build]: Distribution of instances among all 6 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|    crazing    | 103          |   inclusion   | 159          |  patches   | 222          |
| pitted_surf.. | 106          | rolled-in_s.. | 141          | scratches  | 103          |
|               |              |               |              |            |              |
|     total     | 834          |               |              |            |              |
[12/23 16:34:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_l
ength=(800, 800), max_size=1333, sample_style='choice')]
[12/23 16:34:58 d2.data.common]: Serializing 360 elements to byte tensors and concatenating them all ...
[12/23 16:34:58 d2.data.common]: Serialized dataset takes 0.12 MiB
[12/23 16:34:58 d2.evaluation.evaluator]: Start inference on 360 batches
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/structures/boxes.py:158: UserWarning: Creating a ten
sor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with nu
mpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)
/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid:
 in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/nati
ve/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/23 16:35:04 d2.evaluation.evaluator]: Inference done 11/360. Dataloading: 0.0011 s / iter. Inference: 0.4384 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4397 s / iter. ETA=0:02:33
[12/23 16:35:09 d2.evaluation.evaluator]: Inference done 20/360. Dataloading: 0.0014 s / iter. Inference: 0.5078 s / iter.
 Eval: 0.0003 s / iter. Total: 0.5095 s / iter. ETA=0:02:53
[12/23 16:35:14 d2.evaluation.evaluator]: Inference done 33/360. Dataloading: 0.0014 s / iter. Inference: 0.4603 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4620 s / iter. ETA=0:02:31
[12/23 16:35:19 d2.evaluation.evaluator]: Inference done 44/360. Dataloading: 0.0014 s / iter. Inference: 0.4652 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4671 s / iter. ETA=0:02:27
[12/23 16:35:25 d2.evaluation.evaluator]: Inference done 56/360. Dataloading: 0.0014 s / iter. Inference: 0.4603 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4621 s / iter. ETA=0:02:20
[12/23 16:35:30 d2.evaluation.evaluator]: Inference done 68/360. Dataloading: 0.0015 s / iter. Inference: 0.4556 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4574 s / iter. ETA=0:02:13
[12/23 16:35:35 d2.evaluation.evaluator]: Inference done 80/360. Dataloading: 0.0015 s / iter. Inference: 0.4510 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4528 s / iter. ETA=0:02:06
[12/23 16:35:40 d2.evaluation.evaluator]: Inference done 93/360. Dataloading: 0.0015 s / iter. Inference: 0.4420 s / iter.
 Eval: 0.0003 s / iter. Total: 0.4438 s / iter. ETA=0:01:58
[12/23 16:35:46 d2.evaluation.evaluator]: Inference done 104/360. Dataloading: 0.0032 s / iter. Inference: 0.4473 s / iter
. Eval: 0.0003 s / iter. Total: 0.4508 s / iter. ETA=0:01:55
[12/23 16:35:51 d2.evaluation.evaluator]: Inference done 115/360. Dataloading: 0.0031 s / iter. Inference: 0.4514 s / iter
. Eval: 0.0003 s / iter. Total: 0.4548 s / iter. ETA=0:01:51
[12/23 16:35:56 d2.evaluation.evaluator]: Inference done 128/360. Dataloading: 0.0029 s / iter. Inference: 0.4464 s / iter
. Eval: 0.0003 s / iter. Total: 0.4497 s / iter. ETA=0:01:44
[12/23 16:36:02 d2.evaluation.evaluator]: Inference done 139/360. Dataloading: 0.0028 s / iter. Inference: 0.4478 s / iter
. Eval: 0.0003 s / iter. Total: 0.4510 s / iter. ETA=0:01:39
[12/23 16:36:07 d2.evaluation.evaluator]: Inference done 149/360. Dataloading: 0.0027 s / iter. Inference: 0.4514 s / iter
. Eval: 0.0003 s / iter. Total: 0.4544 s / iter. ETA=0:01:35
Traceback (most recent call last):
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 208, in <module>
    launch(
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/launch.py", line 82, in launch
    main_func(*args)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/train_net.py", line 184, in main
    res = Trainer.test(cfg, model)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/engine/defaults.py", line 622, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/evaluation/evaluator.py", line 181, in infer
ence_on_dataset
    outputs = model(inputs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/data2/user/2025/flf/project_zyh/CDFSOD-benchmark/tools/../detectron2/modeling/meta_arch/devit.py", line 1450, in
forward
    embedding = rp(embedding)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in
forward
    input = module(input)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _c
all_impl
    return forward_call(*input, **kwargs)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 463, in forwa
rd
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/fee/sdb_flf/miniconda3/envs/cdfsod/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 459, in _conv
_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.84 GiB (GPU 0; 23.52 GiB total capacity; 8.86 GiB alr
eady allocated; 780.94 MiB free; 12.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try set
ting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
(cdfsod) fee@ubuntu-R8428-A12:~/sdb_flf/project_zyh/CDFSOD-benchmark$ tmux capture-pane -pS -10000 > check_log02.txt

